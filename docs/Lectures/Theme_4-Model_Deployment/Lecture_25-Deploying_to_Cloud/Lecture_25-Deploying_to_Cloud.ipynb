{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbe026a0-1dad-40ef-a202-791e9ab53609",
   "metadata": {},
   "source": [
    "# Lecture 25 - Deploying Projects to the Cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8fe2db-d2a4-463d-86ad-d0c1aae1d7b2",
   "metadata": {},
   "source": [
    "[![View notebook on Github](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=View%20On%20Github&color=lightgrey)](https://github.com/avakanski/Fall-2024-Applied-Data-Science-with-Python/blob/main/docs/Lectures/Theme_4-Model_Deployment/Lecture_25-Deploying_to_Cloud/Lecture_25-Deploying_to_Cloud.ipynb)\n",
    "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/avakanski/Fall-2024-Applied-Data-Science-with-Python/blob/main/docs/Lectures/Theme_4-Model_Deployment/Lecture_25-Deploying_to_Cloud/Lecture_25-Deploying_to_Cloud.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54b18e1-8cdf-4640-92ec-5eceafd13da0",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a id='top'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c93718",
   "metadata": {},
   "source": [
    "- [25.1 Data Science using Cloud Computing](#25.1-data-science-using-cloud-computing)\n",
    "- [25.2 Introduction to Azure Machine Learning](#25.2-introduction-to-azure-machine-learning)\n",
    "    - [25.2.1 Azure Free Trial](#25.2.1-azure-free-trial)\n",
    "- [25.3 No-Code Azure ML](#25.3-no-code-azure-ml)\n",
    "    - [25.3.1 Creating a Workspace Resource](#25.3.1-creating-a-workspace-resource)\n",
    "    - [25.3.2 Using Azure ML Studio](#25.3.2-using-azure-ml-studio)\n",
    "    - [25.3.3 Loading the Dataset](#25.3.3-loading-the-dataset)\n",
    "    - [25.3.4 Creating a Compute Resource](#25.3.4-creating-a-compute-resource)\n",
    "    - [25.3.5 Training a Model with Auto ML](#25.3.5-training-a-model-with-auto-ml)\n",
    "    - [25.3.6 Deploying the Model](#25.3.6-deploying-the-model)\n",
    "    - [25.3.7 Consuming the Model](#25.3.7-consuming-the-model)\n",
    "- [25.4 Code-based Azure ML](#25.4-code-based-azure-ml)\n",
    "    - [25.4.1 Creating Workspace and Compute Resource](#25.4.1-creating-workspace-and-compute-resource)\n",
    "    - [25.4.2 Using Jupyter Notebooks in Azure ML](#25.4.2-using-jupyter-notebooks-in-azure-ml)\n",
    "    - [25.4.3 Loading the Data and Defining the Model](#25.4.3-loading-the-data-and-defining-the-model)\n",
    "    - [25.4.4 Preparing Azure ML Experiment and Training the Model](#25.4.4-preparing-azure-ml-experiment-and-training-the-model)\n",
    "    - [25.4.5 Consuming the Model](#25.4.5-consuming-the-model)\n",
    "- [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bed47f",
   "metadata": {},
   "source": [
    "## 25.1 Data Science using Cloud Computing <a id=\"25.1-data-science-using-cloud-computing\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271810f7-6fc7-4f81-9349-7a0fea3ef7f8",
   "metadata": {},
   "source": [
    "**Cloud Computing**, also referred to as the Cloud, delivers services hosted over a network, which can include data analytics, storage, databases, networking, and other services. The service is often in the form of a *public cloud*  offered to the public over the Internet by cloud service providers, or it can be a *private cloud* that is owned by an organization that maintains the services on a private network. \n",
    "\n",
    "Public Cloud Computing services include Amazon Web Services, Google Cloud Platform, Microsoft Azure, IBM Cloud, and others.\n",
    "\n",
    "In general, Cloud Computing services can be categorized as:\n",
    "\n",
    "- *Infrastructure as a Service (IaaS)*: access to infrastructure, consisting of servers, virtual machines (VMs), storage, networks, or databases.\n",
    "- *Platform as a Service (PaaS)*: access to a platform for developing, testing, delivering, and managing software applications, using infrastructure managed by the provider. \n",
    "- *Software as a Service (SaaS)*: access to software applications, that are developed and managed by the provider using the provider's infrastructure. \n",
    "\n",
    "The advantages of using Cloud Computing include convenient access to the latest computational resources (without the need to purchase hardware or software), access to structured environments (preinstalled libraries) for running tasks, pay for what you need only, ability to quickly scale projects, improved efficiency by relying on infrastructure hosted and managed by the cloud provider, etc.\n",
    "\n",
    "Cloud Computing is especially important for managing  Data Science projects, which often require access to GPUs and large compute resources, storing large amounts of data, access to databases, deploying solutions for access by end-users, and similar. In addition, most Cloud providers have developed some form of AutoML tools that enable organizations without Data Science expertise to implement data analytics workflows into their projects. \n",
    "\n",
    "This lecture is primarily based on a course [Data Science for Beginners](https://github.com/microsoft/Data-Science-For-Beginners/blob/main/5-Data-Science-In-Cloud/18-Low-Code/README.md) by Microsoft. The course has several lectures on deploying Data Science projects to the Cloud, as well as it has other lectures on Data Science in general."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fbf9c2",
   "metadata": {},
   "source": [
    "## 25.2 Introduction to Azure Machine Learning <a id=\"25.2-introduction-to-azure-machine-learning\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db493fb",
   "metadata": {},
   "source": [
    "**Microsoft's Azure Machine Learning** is a cloud platform that provides a large number of products and services designed for handling various phases of Data Science projects. This includes capabilities for preparing and preprocessing data, training models, deploying models, and monitoring models in production. These capabilities can help to increase the efficiency of data scientists by automating many tasks and project pipelines. Understandably, the availability of cloud computing resources allows to easily scale projects and handle efficiently challenges related to processing big data and serving large a number of customers. \n",
    "\n",
    "Important tools and services provided by Azure ML include:\n",
    "\n",
    "- *Azure Machine Learning Studio*: framework for data engineering, model training, and deployment. \n",
    "- *Azure Machine Learning Designer*: low-code ML framework that allows to drag-and-drop modules for building data science pipelines.\n",
    "- *Azure Machine Learning SDK*: code-based environment for data science projects. \n",
    "- *Data Labelling*: tools for automatic data labeling.\n",
    "- *Machine Learning CLI (Command-Line Interface)*: allows managing Azure ML resources from the command line.\n",
    "- *Automated Machine Learning (AutoML) User Interface*: tools to automate tasks in data science projects. \n",
    "- *MLflow*: framework for tracking the performance of deployed models, and logging metrics and relevant indicators. \n",
    "\n",
    "Azure ML allows using Jupyter Notebooks and has built-in integration with popular ML libraries like Scikit-Learn, TensorFlow, PyTorch, and others.\n",
    "\n",
    "In this lecture, we will explore the different levels of functionality of Azure ML, ranging from the no-code AutoML, to full-code SDK, and working with our own custom models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0960c63",
   "metadata": {},
   "source": [
    "### 25.2.1 Azure Free Trial <a id=\"25.2.1-azure-free-trial\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bba6b6",
   "metadata": {},
   "source": [
    "Microsoft Azure has 30 days of free trial, which also can come with a $200 Azure credit that can be used within the 30 days. \n",
    "\n",
    "Also, Azure offers $100 yearly Azure credit to students. \n",
    "\n",
    "In addition, the other Cloud providers typically offer some amount of credit to new users and students.\n",
    "\n",
    "Follow the link to the [Microsoft Azure webpage](https://azure.microsoft.com/en-us/free/) and select the `Start free` button. This will prompt you to create an Azure account, and if you wish you can use your University of Idaho account to get access to Azure. \n",
    "\n",
    "<img src=\"images/Azure_free_trial.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e898607",
   "metadata": {},
   "source": [
    "Once you create an account and get the subscription with $200 Azure credits, the home page should look similar to the following.\n",
    "\n",
    "<img src=\"images/Azure_homepage.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1dedc1-7725-4b23-8c89-d789b59772e0",
   "metadata": {},
   "source": [
    "## 25.3 No-Code Azure ML <a id=\"25.3-no-code-azure-ml\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90a5e50",
   "metadata": {},
   "source": [
    "### 25.3.1 Creating a Workspace Resource<a id=\"25.3.1-creating-a-workspace-resource\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e7cbd1",
   "metadata": {},
   "source": [
    "From the home page, we will need to first create a new **Resource** that will indicate what type of tools and services we will be using. \n",
    "\n",
    "- Select `+ Create a resource`.\n",
    "\n",
    "<img src=\"images/Create_resource.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f11a1ab-a88e-4df5-8d52-fff3a1837d4a",
   "metadata": {},
   "source": [
    "Azure will next display many popular services and resources.\n",
    "\n",
    "- In the search box write `Azure Machine Learning` and select it.\n",
    "\n",
    "<img src=\"images/Resource_search.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07222355-e1ed-4feb-bae7-5caadbd6318c",
   "metadata": {},
   "source": [
    "This will load the web page of Azure Machine Learning. \n",
    "\n",
    "- Select `Create`. \n",
    "\n",
    "It will open a new page for `Azure ML Workspace resource`. The **Workspace** provides a place to work with machine learning models, and allows access to tools for training and deploying models. For instance, the Workspace will store information about training runs, such as logs of various metrics, it will provide access to the data and scripts, etc. And note also that when we are done with using Azure resources such as workspaces, we need to delete the resources, otherwise some costs can be incurred (e.g., even if we don't use the workspace to run a model, Azure may charge a fee for storing the data).\n",
    "\n",
    "<img src=\"images/Create_workspace.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1ceaef",
   "metadata": {},
   "source": [
    "When we create a new Workspace, we need to fill in the information shown in the screenshot below. \n",
    "\n",
    "- Subscription: Azure subscription, e.g., the $200 Azure credits obtained with the free trial. \n",
    "- Resource group: Assign a name for the resource group, or click on `Create new` to create a resource group.\n",
    "- Workspace name: Assign a name for the workspace (e.g., perhaps a name that is related to the project).\n",
    "- Region: Select the geographical region.\n",
    "- Storage account: A new storage account will be created for the workspace for storing the data.\n",
    "- Key vault: A new key vault will be created for the workspace for storing sensitive information.\n",
    "- Application insights: A new application insights resource will be created for the workspace to store information about deployed models.\n",
    "- Container registry: Leave it as None (it will be created automatically the first time the model is deployed).\n",
    "\n",
    "After the information in all fields is entered, select `Review & create`. \n",
    "\n",
    "<img src=\"images/Workspace_form.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958001f2-75eb-4c92-afca-689510ac3586",
   "metadata": {},
   "source": [
    "The next page will show the information that we entered and we will need to confirm that everything is correct.\n",
    "\n",
    "- Select `Create`.\n",
    "\n",
    "<img src=\"images/Workspace_confirm.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ace3e2-c832-4058-8ea0-d1d1eb20f2ff",
   "metadata": {},
   "source": [
    "It may take a few minutes for the Workspace to be created. Once it is ready, the page will show that it is completed. \n",
    "\n",
    "<img src=\"images/Workspace_complete.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ac8375-b80c-4e6d-83e7-c92ad3407b90",
   "metadata": {},
   "source": [
    "### 25.3.2 Using Azure ML Studio<a id=\"25.3.2-using-azure-ml-studio\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11d8a53-4230-4a12-9055-0f81a30dbc63",
   "metadata": {},
   "source": [
    "As we mentioned in the introductory section, **Azure Machine Learning Studio** is a framework for data engineering, model training, and deployment. \n",
    "\n",
    "- Click on the following [link](https://ml.azure.com) to navigate to Azure ML Studio. \n",
    "\n",
    "The interface of Azure ML Studio is shown below. On the top of the page, our workspace should be listed. In this case, the workspace that we just created and named `My_workspace_1` is shown.\n",
    "\n",
    "<img src=\"images/ML_Studio.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd55d6ec-871f-4487-acbb-1beb6d05785d",
   "metadata": {},
   "source": [
    "The various modules that are available in Azure ML Studio are listed in the left-side menu. To see the names of the modules, click on the three horizontal lines in the upper left corner. A brief description of the modules is shown in the next figure. The modules allow to conveniently apply tools for managing different phases of data science projects from a single place. \n",
    "\n",
    "<img src=\"images/ML_modules.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db941ecf",
   "metadata": {},
   "source": [
    "### 25.3.3 Loading the Dataset<a id=\"25.3.3-loading-the-dataset\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462bb07e",
   "metadata": {},
   "source": [
    "For demonstration purposes, we will use the Heart Failure Dataset, which we used before in this course, and contains 13 columns with information about 300 patients who may or may not have risk of heart failure. The `.csv` file with the records is available in the `data` folder with the other files for this lecture.\n",
    "\n",
    "- Click on the `Data` module in the left-side menu in Azure ML Studio (see figure below).\n",
    "\n",
    "The Data section provides various tools for data management, and it allows to upload files or folders with data from a local machine, or provide links to web files (e.g., data from GitHub or Google Drive), load data from a list of open datasets collected by Microsoft (check [Azure Open Datasets](https://learn.microsoft.com/en-us/azure/open-datasets/dataset-catalog)), or use files from a datastore. Datastores allow organizations that have many data files in different locations in Azure to link them together and organize them in a single view.\n",
    "\n",
    "- Select `+ Create` to load the dataset.\n",
    "\n",
    "Azure ML Studio will guide us through several steps for creating the dataset.\n",
    "\n",
    "<img src=\"images/Create_dataset.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27aceffa-3f65-4f64-986d-5dfd9f50361e",
   "metadata": {},
   "source": [
    "On the first page, we will need to enter a name for the dataset, a brief description, and also indicate whether the data is in tabular or other formats. After the information is entered, select `Next`.\n",
    "\n",
    "<img src=\"images/dataset_1.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c3852c-4611-4feb-912a-b9625e65eb15",
   "metadata": {},
   "source": [
    "Afterward, we will indicate that the dataset is saved on our computer and we will upload the dataset from local files.\n",
    "\n",
    "<img src=\"images/dataset_2.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514f44fd-f98c-49f6-b9c1-f6bddf0a4db0",
   "metadata": {},
   "source": [
    "Select Next to skip Step 3 and get to Step 4 where from the dropdown menu we select `Upload` - `Upload files` and navigate to the directory where you have saved the csv file containing the heart failure records.\n",
    "\n",
    "<img src=\"images/dataset_3.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a310cc04-d55a-46cc-8e92-8bfcad4b03be",
   "metadata": {},
   "source": [
    "The next page will show the columns in the dataset. Select `Next` to go to the next page.\n",
    "\n",
    "In the Schema page, we will change the data type to Boolean for the columns `anemia`, `diabetes`, `high blood pressure`, `sex`, `smoking`, and `DEATH_EVENT`.\n",
    "\n",
    "Afterward, click `Next` and select `Create` to complete the creation of the dataset. \n",
    "\n",
    "<img src=\"images/dataset_4.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1000ee08-def7-4da8-9c00-a86894986f6f",
   "metadata": {},
   "source": [
    "Now we can see that the dataset `heart-failure-dataset` is listed under the `Data assets` in our workspace.\n",
    "\n",
    "<img src=\"images/data_created.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff50b7f8-a477-4284-adda-eebe8d503296",
   "metadata": {},
   "source": [
    "### 25.3.4 Creating a Compute Resource<a id=\"25.3.4-creating-a-compute-resource\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579db70a-1b6b-42dc-9478-421b1c489482",
   "metadata": {},
   "source": [
    "We also need to use Compute Resources for our project to perform data preparation and processing, and to run the models. \n",
    "To create a compute resource, we will select `Compute` from the left-side menu. \n",
    "\n",
    "We can see that the compute resources are categorized into four tabs:\n",
    "\n",
    "- Compute Instances, are workstations for data and models; they involve creating a Virtual Machine (VM) and launching a notebook instance (e.g., compute resources to train a model are requested from the notebook). \n",
    "- Compute Clusters, VMs for on-demand code processing (e.g., training a model using AutoML).\n",
    "- Kubernetes Clusters, VMs that are orchestrated by Kubernetes.\n",
    "- Attached Compute, links to existing Azure compute resources, such as Virtual Machines or Azure Databricks clusters.\n",
    "\n",
    "<img src=\"images/compute_module.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff6d946-861b-4b8d-aa34-0bd590057848",
   "metadata": {},
   "source": [
    "For this task, we can use either a compute instance or compute cluster, so let's select the `Compute instances` tab.\n",
    "\n",
    "- Click on the `+ New` button to create a new compute resource.\n",
    "- Let's assign the name `heart-failure-compute` for the resource (see the figure below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb84afa-9271-4245-95c7-9161a3fd2a1a",
   "metadata": {},
   "source": [
    "Selecting adequate compute resources for a project depends on several factors, which impose trade-offs between speed and cost. \n",
    "\n",
    "1. *CPU versus GPU*: CPUs are less expensive, but also less powerful especially for training deep learning models. GPUs are more expensive, but they provide efficient parallel computing, and are often necessary for training deep learning models. \n",
    "2. *Cluster size*: larger clusters are more expensive, but faster in completing tasks. For smaller tasks that don't take too long, it may be better to select a small compute cluster. \n",
    "3. *VM size*: similar to the cluster size, increasing the amount of RAM, number of cores, and processing speed of the VMs will reduce the computational time, but it will be more expensive.\n",
    "4. *Dedicated versus low-priority resources*: dedicated resources are non-interruptible, while low-priority instances can be assigned by Azure to other tasks and interrupt the job. \n",
    "\n",
    "For this project, we will select a VM with a CPU, and from the listed VMs we can select the one with optimized memory, which costs $0.32 per hour. \n",
    "\n",
    "There are several optional steps that we can skip and click on `Review + Create` to create the compute instance.\n",
    "\n",
    "It can take a few minutes for the compute resource to be created.\n",
    "\n",
    "<img src=\"images/VM.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad2a3ae-926a-424d-a7f0-bfbd73b7e4cd",
   "metadata": {},
   "source": [
    "### 25.3.5 Training a Model with Auto ML <a id=\"25.3.5-training-a-model-with-auto-ml\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42be31d-435b-496c-982f-9c7cd6e36a65",
   "metadata": {},
   "source": [
    "AutoML in Azure ML Studio allows to build and deploy ML models without writing code. \n",
    "\n",
    "- Select `Automated ML` from the modules in the left-side panel.\n",
    "- Select `+ New Automated ML job`.\n",
    "\n",
    "<img src=\"images/autoML.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaadede-2e09-43ab-ab91-d5de19a4acb2",
   "metadata": {},
   "source": [
    "- The first step requires to assign a name for the experiment. Let's simply name it `Heart_failure_experiment`.\n",
    "\n",
    "<img src=\"images/autoML_experiment.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c49e910-5a20-4fa2-a384-e3b7f6cf2d50",
   "metadata": {},
   "source": [
    "- Afterward, we need to indicate the *task*, that is, whether the goal is to perform classification, regression, time-series forecasting, etc. In this case, we select `classification`.\n",
    "- For dataset, we will select the `heart-failure-dataset` that we uploaded.\n",
    "\n",
    "<img src=\"images/autoML_task.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3779356-8b02-40ef-b458-a57a45e1cbfc",
   "metadata": {},
   "source": [
    "- Next, select a target column in the data: in this case it is `DEATH_EVENT`.\n",
    "- We can also specify the validation type, e.g., whether we would like to use k-fold cross-validation, or whether to split the training data into train and validation sets, etc. Also, the test data asset field allows to upload a test dataset or specify how to evaluate the model. We can leave these fields at their defaults.\n",
    " \n",
    "<img src=\"images/autoML_task_settings.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abae900b-74ff-4944-a11b-c475867f1600",
   "metadata": {},
   "source": [
    "- Finally, use the drop-down menu to assign a compute resource, e.g., select the `heart-failure-compute` that we created.\n",
    "- Review the AutoML job and submit it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeeeaee-0ba7-49dd-bd09-17ed8cea2507",
   "metadata": {},
   "source": [
    "Now the setup is complete, the experiment will begin running. This means that Azure ML will train many different models, and explore different hyperparameters for the models. \n",
    "\n",
    "On the home page, under the `Jobs`section, we will see a summary of the entered information about the experiment, and we will also see that the status of the experiment is `Running`. It took about 1 hour to complete this experiment. \n",
    "\n",
    "<img src=\"images/running.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13ecbf0-4f1a-4e58-8bd0-fff038d062f8",
   "metadata": {},
   "source": [
    "When the experiment is completed, in the `Best model summary` we can see that the highest performance was obtained by a Voting Ensemble model, which achieved 91.526% AUC. \n",
    "\n",
    "<img src=\"images/autoML_summary.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6159734c-a22e-4ff3-9f21-c30becf5af8e",
   "metadata": {},
   "source": [
    "Also, let's select the `Models` tab to get more information about the training. We can see that over 50 models were trained in total, including LightGBM, XGBoost, Random Forest, Gradient Boosting, and running most of the models took under 1 minute. We can also see that different scaling methods were used with different algorithms (MinMaxScaler, RobustScaler, StandardScaler).\n",
    "\n",
    "<img src=\"images/models.png\" width=\"1000\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0853eb0-3828-4335-bde5-e47bd4d10b56",
   "metadata": {},
   "source": [
    "### 25.3.6 Deploying the Model <a id=\"25.3.6-deploying-the-model\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d08d37-eb58-4fd8-aa5d-c5cedbe02b1f",
   "metadata": {},
   "source": [
    "To deploy a trained model as a web service, we will select the Voting Ensemble as the best model, and from the drop-down menu under the `Deploy` tab select `Web service`. \n",
    "\n",
    "<img src=\"images/deploy.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d56eca-cb3a-4b95-9f85-8dad1280ec95",
   "metadata": {},
   "source": [
    "In the newly opened form, we need to assign a name for the deployed model, a brief description, and compute type for the deployed model. In this case, we selected Azure Container Instance, which is suitable for low-scale CPU-based workloads, as is the model for this project. Deploying models that require large computational resources can require using other compute type with GPUs, larger RAM memory, or larger number of cores. \n",
    "\n",
    "Next, let's click on `Deploy` to initialize this step. It took about 15 minutes for this project to be deployed. When it is completed, the `Deploy Status` on the dashboard will change from Running to Succeeded. \n",
    "\n",
    "<img src=\"images/deploy_form.png\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfca75e2-9b5b-4340-9241-ed0ca499f094",
   "metadata": {},
   "source": [
    "### 25.3.7 Consuming the Model <a id=\"25.3.7-consuming-the-model\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819d3b18-3ed7-4cac-9fbc-e418a005f33b",
   "metadata": {},
   "source": [
    "After the model is deployed, we can find the summarized information in the `Endpoints` module in the left-hand menu.\n",
    "\n",
    "- Select the `Consume` tab to access the script for consuming the model. \n",
    "\n",
    "The Consume page will provide the REST endpoint for users' consumption, the primary and secondary API keys for authentication, and a script for consuming the model from a local machine. The script is available in Python, C#, and R. \n",
    "\n",
    "<img src=\"images/endpoint.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21192331-ed2f-4b15-b4a5-f11a857e5acf",
   "metadata": {},
   "source": [
    "The Python script is shown below. The `data` section represents a dictionary where the users enter information for the input features. In this script, all values are set either to 0 or False. Then, the `url` in the code below is the address for the REST endpoint from the above figure, and `api_key` is the primary authentication key that is listed in the above figure as well. The last code section makes a prediction for the `DEATH_EVENT`, and the result is displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e925df-4252-495f-a67e-5285e51d49b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "```python\n",
    "# Note: the codes in this lecture are not required for quizzes or assignments\n",
    "\n",
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "# Request data goes here\n",
    "# The example below assumes JSON formatting which may be updated\n",
    "# depending on the format your endpoint expects.\n",
    "# More information can be found here:\n",
    "# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script\n",
    "data =  {\n",
    "  \"Inputs\": {\n",
    "    \"data\": [\n",
    "      {\n",
    "        \"age\": 0.0,\n",
    "        \"anaemia\": False,\n",
    "        \"creatinine_phosphokinase\": 0,\n",
    "        \"diabetes\": False,\n",
    "        \"ejection_fraction\": 0,\n",
    "        \"high_blood_pressure\": False,\n",
    "        \"platelets\": 0.0,\n",
    "        \"serum_creatinine\": 0.0,\n",
    "        \"serum_sodium\": 0,\n",
    "        \"sex\": False,\n",
    "        \"smoking\": False,\n",
    "        \"time\": 0\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  \"GlobalParameters\": {\n",
    "    \"method\": \"predict\"\n",
    "  }\n",
    "}\n",
    "\n",
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "url = 'http://a836b469-9573-4a63-bd31-90e8205ae13c.westus2.azurecontainer.io/score'\n",
    "api_key = 'QYEGDiZFpL5OECR2aZEhhNfSfYhPvgVn' # Replace this with the API key for the web service\n",
    "\n",
    "# The azureml-model-deployment header will force the request to go to a specific deployment.\n",
    "# Remove this header to have the request observe the endpoint traffic rules\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(error.read().decode(\"utf8\", 'ignore'))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bab0c7f-7da9-4722-b8a3-96942fc24c74",
   "metadata": {},
   "source": [
    "To consume the model, we just need to save the script to our local machine and execute it. The output is shown below. For this set of input parameters, the result for DEATH_EVENT is `True`.\n",
    "\n",
    "<img src=\"images/result_1.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6466b2-cc0f-4b4b-856a-932dc99c0472",
   "metadata": {},
   "source": [
    "Let's check the model prediction for the last record in the dataset. The input features are shown below. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e3f594-c909-4f7d-aea8-610af578eda4",
   "metadata": {},
   "source": [
    "```python\n",
    "\"age\": 50.0,\n",
    "\"anaemia\": False,\n",
    "\"creatinine_phosphokinase\": 196,\n",
    "\"diabetes\": False,\n",
    "\"ejection_fraction\": 45,\n",
    "\"high_blood_pressure\": False,\n",
    "\"platelets\": 395000.0,\n",
    "\"serum_creatinine\": 1.6,\n",
    "\"serum_sodium\": 136,\n",
    "\"sex\": True,\n",
    "\"smoking\": True,\n",
    "\"time\": 285\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0ad532-8d1d-475e-8227-c6a379b142b4",
   "metadata": {},
   "source": [
    "The prediction by the model is `False` as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d6ed7f-284b-4434-922f-12847f4909d6",
   "metadata": {},
   "source": [
    "<img src=\"images/result_2.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a6d53-8fdb-484f-8a95-c5210078c276",
   "metadata": {},
   "source": [
    "## 25.4 Code-based Azure ML <a id=\"25.4-code-based-azure-ml\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c537d9b-8dc9-48b4-80c1-5cf3603fc324",
   "metadata": {},
   "source": [
    "In this section, we will use **Azure ML Studio** to manage Data Science projects in a Python environment, that can include Jupyter Lab, Jupyter Notebooks, or VS Code. Differently from the previous section which focused on No-Code environment with Azure ML Studio, this section focuses on Code-based environment with Azure ML Studio. \n",
    "\n",
    "We will learn how to use Azure ML to train our own custom model. For this purpose, we will define a deep learning model for classification of the MNIST dataset, and we will train and evaluate the model using Azure ML resources. Afterward, we will deploy the model, and test the deployment. \n",
    "\n",
    "If we didn't have access to GPUs from other sources, we could use the GPUs provided by Azure ML to train our models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743b628e-d24b-48bf-953d-c425c8675893",
   "metadata": {},
   "source": [
    "### 25.4.1 Creating Workspace and Compute Resource<a id=\"25.4.1-creating-workspace-and-compute-resource\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c80b4cc-aae1-49c7-95b5-df724f36bd50",
   "metadata": {},
   "source": [
    "Let's log in to the [Microsoft Azure webpage](https://azure.microsoft.com/en-us/free/) and create a new workspace named `Workspace_2`, by following the steps listed in Section 25.3.\n",
    "\n",
    "Afterward, we will navigate to the [Azure ML Studio webpage](https://ml.azure.com), and in the newly created `Workspace_2`, we will create a new compute resource from the `Compute` module in the left-side menu. Similar to the previous section, we will select the `Compute instances` tab and click on `+ New`. For this task, we can use a CPU VM since MNIST is a relatively small dataset. If we were to work with larger datasets and models, we would need to select a GPU VM.  \n",
    "\n",
    "<img src=\"images/resources_2.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99bc1f2-7c7a-4a7b-a391-780e051ba768",
   "metadata": {},
   "source": [
    "### 25.4.2 Using Jupyter Notebooks in Azure ML<a id=\"25.4.2-using-jupyter-notebooks-in-azure-ml\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47eddcab-3973-4778-bb8d-e2e79257d933",
   "metadata": {},
   "source": [
    "The created compute instance will be listed on our homepage. Note that in the Applications tab, the listed applications include `Jupyter Lab`, `Jupyter`, and `VS Code`. We can use these applications to work with Jupyter Notebook files in the same way as we do outside of Azure ML Studio.\n",
    "\n",
    "Let's select `Jupyter Lab` from the Applications tab for the newly created compute instance. \n",
    "\n",
    "<img src=\"images/jupyter_1.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e304a07-eae5-48b3-8403-08e04bb365a2",
   "metadata": {},
   "source": [
    "### 25.4.3 Loading the Data and Defining the Model<a id=\"25.4.3-loading-the-data-and-defining-the-model\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcaa8cf-7065-4d67-8594-e0392363a259",
   "metadata": {},
   "source": [
    "In the opened Jupyter Lab environment let's create a new notebook for training the model using `Python 3.8 - Pytorch and Tensorflow` kernel.\n",
    "\n",
    "Let's rename the notebook to `mnist-demo`. \n",
    "\n",
    "The code in the next cells is familiar, and it simply imports libraries and loads the MNIST dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4481668-3829-40c6-94c2-1c86bfe3fd26",
   "metadata": {},
   "source": [
    "```python\n",
    "# Import libraries\n",
    "import urllib.request\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d781f290-da13-4509-948b-e1967a813af7",
   "metadata": {},
   "source": [
    "```python\n",
    "# Load the data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('Data shape:', X_train.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e0d36-90a7-4e4f-a999-6baf28492efa",
   "metadata": {},
   "source": [
    "We will use TensorFlow-Keras library to define a simple Convolutional Neural Network for MNIST classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4a7e20-0f69-43e9-b72b-3bf4efa31c24",
   "metadata": {},
   "source": [
    "```python\n",
    "# Define the layers in the model\n",
    "inputs = Input(shape=(28, 28, 1))\n",
    "conv1a = Conv2D(filters=32, kernel_size=3, padding='same')(inputs)\n",
    "conv1b = Conv2D(filters=64, kernel_size=3, padding='same')(conv1a)\n",
    "pool1 = MaxPooling2D()(conv1b)\n",
    "flat = Flatten()(pool1)\n",
    "dense1 = Dense(1024, activation='relu')(flat)\n",
    "dropout1 = Dropout(0.5)(dense1)\n",
    "outputs = Dense(10, activation='softmax')(dropout1)\n",
    "\n",
    "# Define the model with inputs and outputs\n",
    "model = Model(inputs, outputs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ad3dc9-5f15-41e4-bf00-46c93ee7a576",
   "metadata": {},
   "source": [
    "```python\n",
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=[\"accuracy\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ac1640-5f13-466b-bb46-a564b45e4750",
   "metadata": {},
   "source": [
    "### 25.4.4 Preparing Azure ML Experiment and Training the Model<a id=\"25.4.4-preparing-azure-ml-experiment-and-training-the-model\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9407ff4-c8a4-4bdd-b66b-e4364509b9f5",
   "metadata": {},
   "source": [
    "Next, we will create an Azure ML experiment, and we will associate it with the current workspace and the subscription information. Hence, we will assign the workspace name to the current `Workspace_2` using the information about our `Subscription` and `Resource group`. \n",
    "\n",
    "Afterward, we will instantiate a new experiment named `demo-mnist-training` that will utilize the created Azure ML workspace and resources to train and deploy the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a03d31-2c6b-46f1-a1f8-139e5900f23b",
   "metadata": {},
   "source": [
    "```python\n",
    "from azureml.core import Workspace, Experiment\n",
    "\n",
    "SUBSCRIPTION=\"...enter you 32-digit subscription number here...\"\n",
    "GROUP=\"My_resource_group_1\"\n",
    "WORKSPACE=\"Workspace_2\"\n",
    "\n",
    "# Create an instance of the Workspace class using the subscription information\n",
    "ws = Workspace(\n",
    "    subscription_id=SUBSCRIPTION,\n",
    "    resource_group=GROUP,\n",
    "    workspace_name=WORKSPACE,\n",
    ")\n",
    "\n",
    "# Create an Azure ML experiment within the workspace \"ws\"\n",
    "experiment = Experiment(ws, \"demo-mnist-training\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5f07d6-4763-473d-a484-354bac87523d",
   "metadata": {},
   "source": [
    "Azure ML allows integration of the `MLflow` framework for managing and tracking ML experiments.  \n",
    "\n",
    "In the next cell, we import `MLFLow` and we will use it to automatically log the loss, accuracy, and other parameters of the training progress for the TensorFlow model with the `autolog()` method. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e9a4c7-7fd0-4d88-b637-6a5851b182d4",
   "metadata": {},
   "source": [
    "```python\n",
    "import mlflow, mlflow.tensorflow\n",
    "\n",
    "# Track the experiment and log the training progress\n",
    "mlflow.set_tracking_uri(ws.get_mlflow_tracking_uri())\n",
    "mlflow.start_run(experiment_id=experiment.id)\n",
    "mlflow.tensorflow.autolog()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111df598-7dac-449e-ac75-40c70fe4a8f3",
   "metadata": {},
   "source": [
    "Next, we train the model for 5 epochs, and we can see that it achieved close to 99% train accuracy. \n",
    "\n",
    "Afterward, we terminate the `MLFlow` run, and save the model in the current directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2b8839-a3c8-4a01-b2f9-939962497350",
   "metadata": {},
   "source": [
    "```python\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1270b46e-bdb6-40d4-8c70-7b3fff199da8",
   "metadata": {},
   "source": [
    "<img style=\"float: center; height:150px;\" src=\"images/mnist_fit.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ee1e67-9f8d-41c9-b561-8fa1d3b7b66a",
   "metadata": {},
   "source": [
    "```python\n",
    "# End the mlflow run\n",
    "mlflow.end_run()\n",
    "\n",
    "# Save the model\n",
    "model.save('mnist-tf-model.h5')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dc7341-8f16-4042-a7c8-7df78827b08d",
   "metadata": {},
   "source": [
    "### 25.4.5 Consuming the Model<a id=\"25.4.5-consuming-the-model\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662364e4-b4d7-43cd-a559-6c0d17e170d4",
   "metadata": {},
   "source": [
    "To consume the model, first we will register the model with Azure ML so that it can be used for inference in the future. This will save the model under the name `mnist-tf-model` and it will register it to our workspace. The registered model can be accessed from the `Models` section under `Assets` in the left-side panel in Azure ML Studio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c185f8a-4071-42c2-beb5-9d89b4b10ecb",
   "metadata": {},
   "source": [
    "```python\n",
    "# Register the model\n",
    "from azureml.core.model import Model\n",
    "\n",
    "registered_model = Model.register(\n",
    "    workspace=ws,\n",
    "    model_name='mnist-tf-model',\n",
    "    model_path='mnist-tf-model.h5',\n",
    "    model_framework=Model.Framework.TENSORFLOW,\n",
    "    model_framework_version=tf.__version__)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8393acc0-00d7-4958-a760-13b5c53926c6",
   "metadata": {},
   "source": [
    "Afterward, we will load the registered model and use it to predict the classes for several images. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2575c77-eee1-4728-8ecf-cd1ca7031a19",
   "metadata": {},
   "source": [
    "```python\n",
    "# load the registered model\n",
    "aml_model = Model(workspace=ws, name='mnist-tf-model', version=registered_model.version)\n",
    "\n",
    "downloaded_model_filename = aml_model.download(exist_ok=True)\n",
    "print(downloaded_model_filename)\n",
    "\n",
    "downloaded_model = tf.keras.models.load_model(downloaded_model_filename)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e62294-9323-47e6-a6cd-898e48941187",
   "metadata": {},
   "source": [
    "```python\n",
    "# Evaluate the model\n",
    "downloaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd63fb0-5bf9-4fcd-b5c2-d274ef4488d1",
   "metadata": {},
   "source": [
    "<img src=\"images/test_accuracy.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516cdd20-9369-4ccc-afe2-fc77b95162d0",
   "metadata": {},
   "source": [
    "```python\n",
    "# Predict the labels for several images\n",
    "preds = downloaded_model.predict(X_test).argmax(axis=1)\n",
    "show_images(X_test[:10], preds[:10])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543ce604-3245-4b59-90de-734d1c51e0e3",
   "metadata": {},
   "source": [
    "<img src=\"images/show_images_2.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5705ef-c4c9-4ab9-b652-66a1f41b63f6",
   "metadata": {},
   "source": [
    "As we mentioned earlier, always remember to release the used compute resources after training or predicting with a model. One alternative is to `Stop` the current compute resource from running if we would like to reuse it later, or `Delete` the resources if they are not needed for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a67b11-cb16-42a4-8097-94a3456e828c",
   "metadata": {},
   "source": [
    "<img src=\"images/clean_resource.png\" width=\"700\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389368f9",
   "metadata": {},
   "source": [
    "## References <a id=\"references\"/>\n",
    "\n",
    "1. Microsoft course - Data Science for Beginners, available at [https://github.com/microsoft/Data-Science-For-Beginners](https://github.com/microsoft/Data-Science-For-Beginners).\n",
    "2. From No-Code to Code in Azure Machine Learning, by William VanBuskirk, available at: [https://levelup.gitconnected.com/from-no-code-to-code-in-azure-machine-learning-38ee6b556de2](https://levelup.gitconnected.com/from-no-code-to-code-in-azure-machine-learning-38ee6b556de2).\n",
    "3. Creating a TensorFlow Model with Python and Azure ML Studio, by Jarek Szczegielniak, available at [https://www.codeproject.com/Articles/5321728/Python-Machine-Learning-on-Azure-Part-3-Creating-a](https://www.codeproject.com/Articles/5321728/Python-Machine-Learning-on-Azure-Part-3-Creating-a)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e12fc40",
   "metadata": {},
   "source": [
    "[BACK TO TOP](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
