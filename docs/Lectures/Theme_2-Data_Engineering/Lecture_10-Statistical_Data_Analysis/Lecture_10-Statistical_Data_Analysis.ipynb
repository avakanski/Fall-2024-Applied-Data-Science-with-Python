{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 10 - Statistical Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![View notebook on Github](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=View%20On%20Github&color=lightgrey)](https://github.com/avakanski/Fall-2024-Applied-Data-Science-with-Python/blob/main/docs/Lectures/Theme_2-Data_Engineering/Lecture_10-Statistical_Data_Analysis/Lecture_10-Statistical_Data_Analysis.ipynb)\n",
    "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/avakanski/Fall-2024-Applied-Data-Science-with-Python/blob/main/docs/Lectures/Theme_2-Data_Engineering/Lecture_10-Statistical_Data_Analysis/Lecture_10-Statistical_Data_Analysis.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [10.1 Descriptive Statistics](#10.1-descriptive-statistics)\n",
    "    - [10.1.1 Measures of Central Tendency](#10.1.1-measures-of-central-tendency)\n",
    "    - [10.1.2 Measures of Variability](#10.1.2-measures-of-variability)\n",
    "    - [10.1.3 Summary of Descriptive Statistics](#10.1.3-summary-of-descriptive-statistics)\n",
    "    - [10.1.4 Measures of Correlation](#10.1.4-measures-of-correlation)\n",
    "- [10.2 Inferential Statistics](#10.2-inferential-statistics)\n",
    "    - [10.2.1 Linear Regression](#10.2.1-linear-regression)\n",
    "    - [10.2.2 Standard Error of the Mean](#10.2.2-standard-error-of-the-mean)\n",
    "    - [10.2.3 Confidence Intervals](#10.2.3-confidence-intervals)\n",
    "    - [10.2.4 Hypothesis Testing](#10.2.4-hypothesis-testing)\n",
    "- [References](#references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistical data analysis is an essential aspect of data science and machine learning. Via statistical data analysis, we can obtain meaningful insights from datasets, make predictions, and inform decision-making. In this lecture, we will cover Python libraries for statistical analysis, including the calculation of descriptive statistics and inferential statistics. Descriptive statistics involves methods for summarizing and organizing data to describe their main features and characteristics. The data summarization is typically in the form of summary statistics and visualization techniques. Inferential statistics involves methods for making inferences or predictions about a population based on a sample of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1 Descriptive Statistics <a id=\"10.1-descriptive-statistics\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descriptive statistics provide basic summaries about a dataset and insights into the characteristics of a dataset. In Data Science, descriptive statistics are often the first step in data exploration, enabling to understand the underlying patterns of the data, detect anomalies, and form hypotheses for further analysis. The initial examination is important for guiding subsequent analyses, which may involve inferential statistics or machine learning model development.\n",
    "\n",
    "Providing data summaries via descriptive statistics can involve:\n",
    "* Calculating **quantitative measures** that describe and summarize the data numerically.\n",
    "* Using **visualization techniques** to present data distributions and relationships with charts and plots.\n",
    "\n",
    "We can apply descriptive statistics to analyze a single variable (feature), or the relationship between multiple variables (features) within a dataset. The type of analysis that focuses on understanding the basic characteristics of a single feature in isolation is referred to as **uinivariate analysis**. Statistical analysis that  examines the relationships and patterns among multiple variables is **multivariate analysis**. The special case of examining the statistical relationships among a pair of variables is called **bivariate analysis**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantitative descriptive statistics measures are typically categorized into:\n",
    "\n",
    "* Measures of **central tendency**, such as the mean, mode, and median, describe the center of the data and indicate where most data points are concentrated.\n",
    "* Measures of **variability**, such as the range, variance, and standard deviation, quantify the spread or dispersion of the data and show how much the data points differ from the central values.\n",
    "* Measures of **correlation**, such as correlation coefficient and covariance, quantify the relationships between variables in a dataset.\n",
    "\n",
    "Additionally, measures like skewness and kurtosis describe the shape of the data distribution, highlighting asymmetry or the presence of outliers in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.1 Measures of Central Tendency <a id=\"10.1.1-measures-of-central-tendency\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The measures of central tendency describe the central or middle values of a dataset, i.e., the location where  most data points are concentrated.\n",
    "\n",
    "The measures of central tendency include:\n",
    "\n",
    "* Mean\n",
    "* Median\n",
    "* Mode\n",
    "* Weighted mean\n",
    "* Geometric mean\n",
    "* Harmonic mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **mean** of a sample drawn from a population is the arithmetic average of all elements in a dataset. It is also called the **sample arithmetic mean** or simply the **average**.\n",
    "\n",
    "The mean of a dataset ùë• is mathematically expressed as:\n",
    "\n",
    "$\\overline{x} = \\frac{\\sum_{i=1}^{n} x_i}{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python we can calculate the mean of a sequence of items using the built-in functions `sum()` and `len()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.7"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [8.0, 1, 2.5, 4, 28.0]\n",
    "\n",
    "mean = sum(x) / len(x)\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, it may be more convenient to import the built-in Python library `statistics` for calculating descriptive statistics and for performing other types of statistical analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.7"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "mean = statistics.mean(x)\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we learned in the previous lectures, the libraries `NumPy` and `pandas` allow calculating descriptive statistics for data in the form of ndarrays and DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# NumPy\n",
    "y = np.array(x)\n",
    "\n",
    "mean = np.mean(y)\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `average()` function in `NumPy` can also be used to calculate the mean of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean = np.average(y)\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# pandas\n",
    "z = pd.Series(x)\n",
    "\n",
    "mean = z.mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A limitation of the mean is its sensitivity to outliers in the dataset having extremely high or low values. Also,  it may not accurately reflect the central tendency if the dataset is skewed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **median** of a sample is the middle element of the sorted elements. The dataset can be sorted in increasing or decreasing order. If the number of elements $ùëõ$ of the dataset is odd, the median is the value at the middle position. If $ùëõ$ is even, the median is the arithmetic mean of the two values in the middle. For example, for the data points `(2, 4, 1, 8, 9)`, the sorted dataset is `(1, 2, 4, 8, 9)`, and the median value is 4. If the data points are `(2, 4, 1, 8)`, the sorted dataset is `(1, 2, 4, 8)`, and the median is 3, obtained as the average of the two middle elements 2 and 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the median in native Python, we can write a simple function based on the above description. However, to avoid any errors in our code, we can simply use the implemented function from the `statistics` library. The sorted version of the above list  `x` is `(1, 2.5, 4, 8.0, 28.0)`, therefore, the median is the element in the middle, which is 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median = statistics.median(x)\n",
    "median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Numpy` and `pandas` also provide a `median` function for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy: 4.0\n",
      "\n",
      "pandas: 4.0\n"
     ]
    }
   ],
   "source": [
    "# NumPy\n",
    "median = np.median(y)\n",
    "print('NumPy:', median)\n",
    "\n",
    "# pandas\n",
    "median = z.median()\n",
    "print('\\npandas:', median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The median is less sensitive to outliers compared to the mean, and therefore, it is considered a more robust measure of central tendency. The median is also particularly useful for skewed distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **mode** of a sample is the value in the dataset that occurs most frequently. For example, in the set that contains the points `(2, 3, 2, 8, 12)`, the number 2 is the mode because it occurs twice. In general, a dataset can have multiple values that occur the most frequently, in which case it is referred to as a multimodal dataset (e.g., if a dataset has two modes, it is called bimodal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics: 2\n"
     ]
    }
   ],
   "source": [
    " u = [2, 3, 2, 8, 12]\n",
    "\n",
    "# statistics\n",
    "mode = statistics.mode(u)\n",
    "print('statistics:', mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `NumPy` does not have a built-in `mode` function. For this purpose, we can use the `scipy.stats` module in the `SciPy` library for scientific calculations which is implemented on top of `NumPy`. The output includes the value of the mode, and the number of counts it occurs in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy: ModeResult(mode=2, count=2)\n"
     ]
    }
   ],
   "source": [
    "# NumPy\n",
    "import scipy\n",
    "mode = scipy.stats.mode(u)\n",
    "print('NumPy:', mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `pandas` to calculate the mode as well. Pandas returns a series with all modes in the dataset, and in this case, the only mode is 2, and it has index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas: 0    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# pandas\n",
    "w = pd.Series(u)\n",
    "mode = w.mode()\n",
    "print('pandas:', mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see another example of a sequence with two modes. Note that the `mode()` function in the `statistics` library returns only a single mode, and the `multimode()` function returns more than one modal value, as shown in the next cell. Therefore, it is preferred to use the `multimode()` function to avoid missing multimodality in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics: 12\n"
     ]
    }
   ],
   "source": [
    "v = [12, 15, 12, 15, 21, 15, 12]\n",
    "\n",
    "# statistics\n",
    "mode = statistics.mode(v)\n",
    "print('statistics:', mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistics: [12, 15]\n"
     ]
    }
   ],
   "source": [
    "# statistics\n",
    "mode = statistics.multimode(v)\n",
    "print('statistics:', mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell shows the same example with `NumPy` and `pandas`. Note that `NumPy` returned only one mode, and it does not have a function for dealing with multiple modes. On the other hand, `pandas` returned both modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy: ModeResult(mode=12, count=3)\n",
      "\n",
      "pandas: 0    12\n",
      "1    15\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# NumPy\n",
    "mode = scipy.stats.mode(v)\n",
    "print('NumPy:', mode)\n",
    "\n",
    "# pandas\n",
    "w = pd.Series(v)\n",
    "mode = w.mode()\n",
    "print('\\npandas:', mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **weighted mean**  is a generalization of the arithmetic mean that enables to assign a weight to each data point that quantifies the relative contribution of the data point to the result. It is also called weighted arithmetic mean or weighted average. \n",
    "\n",
    "If we denote the weight $ùë§_i$ that is assigned to data point $ùë•_i$ of the dataset, the weighted mean is obtained by multiplying each data point with the corresponding weight, summing all the products, and dividing the sum with the sum of the weights:\n",
    "\n",
    "$\\overline{x}_\\text{weighted} = \\frac{\\sum_{i=1}^{n} w_i x_i}{\\sum_{i=1}^{n} w_i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weighted mean is very useful when we need to calculate the mean of a dataset containing items that occur with given relative frequencies. In this case, we consider the frequencies as the weights of the individual data points.\n",
    "\n",
    "The libraries `statistics` and `pandas` do not have functions for calculating the weighted mean. However, it can be easily applied in Python as the example in the next cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.95"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [8.0, 1, 2.5, 4, 28.0]\n",
    "w = [0.1, 0.2, 0.3, 0.25, 0.15]\n",
    "\n",
    "wmean = sum(w[i] * x[i] for i in range(len(x))) / sum(w)\n",
    "wmean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `NumPy`, the `average` function allows to assign weights and calculate the weighted mean. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.95"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmean = np.average(z, weights=w)\n",
    "wmean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Harmonic Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **harmonic mean** is the reciprocal of the mean of the reciprocals of all items in the dataset, i.e.:\n",
    "\n",
    "$\\overline{x}_\\text{harmonic} = \\frac{ùëõ}{\\sum_{i=1}^{n}\\frac{1}{ùë•_i}}$\n",
    "\n",
    "One variant of pure Python implementation of the harmonic mean is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7613412228796843"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmean = len(x) / sum(1/item for item in x)\n",
    "hmean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate this measure with `statistics.harmonic_mean()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7613412228796843"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmean = statistics.harmonic_mean(x)\n",
    "hmean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to calculate the harmonic mean is by using `scipy.stats.hmean()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7613412228796843"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.hmean(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geometric Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **geometric mean** is the ùëõ-th root of the product of all ùëõ elements $ùë•_i$ in a dataset:\n",
    "\n",
    "$\\overline{x}_\\text{geometric} = \\sqrt[n]{\\prod_{i=1}^{n} x_i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be calculated by `statistics.geometric_mean()` and `scipy.stats.gmean()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.67788567485604"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmean = statistics.geometric_mean(x)\n",
    "gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.67788567485604"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.gmean(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.2 Measures of Variability <a id=\"10.1.2-measures-of-variability\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The measures of central tendency are not sufficient to describe data, and we also need the measures of variability that quantify the spread of data points. \n",
    "\n",
    "Measures of variability include:\n",
    "\n",
    "* Range\n",
    "* Interquartile range\n",
    "* Variance\n",
    "* Standard deviation\n",
    "* Skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **range** of a dataset is the difference between the maximum and minimum elements. \n",
    "\n",
    "To calculate the range, we can use `max()` and `min()` from the Python standard library.\n",
    "\n",
    "In NumPy, we can use `np.ptp()` to calculate the range directly, or via `amax()` and `amin()`.\n",
    "\n",
    "Similarly, in `pandas` we can use `.max()` and `.min()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 27.0\n",
      "NumPy: 27.0\n",
      "NumPy: 27.0\n",
      "pandas: 27.0\n"
     ]
    }
   ],
   "source": [
    "range_x = max(x) - min(x)\n",
    "print('Python:', range_x)\n",
    "\n",
    "range_y = np.ptp(y)\n",
    "print('NumPy:', range_y)\n",
    "\n",
    "range_y = np.amax(y) - np.amin(y)\n",
    "print('NumPy:', range_y)\n",
    "\n",
    "range_z = z.max() - z.min()\n",
    "print('pandas:', range_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with range, we need to recall that this statistic is sensitive to outliers in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interquartile Range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **interquartile range** (IQR) is the difference between the first and third quartiles. More specifically, IQR is calculated as the difference between the 25th percentile (first quartile) and 75th percentile (third quartile). \n",
    "\n",
    "A dataset has three quartiles, which divide the dataset into four parts. The *first quartile* (Q1) is the 25th percentile, and it divides approximately 25% of the smallest items from the rest of the dataset. The *second quartile* (Q2) is the 50th percentile, or the median. The *third quartile* (Q3) is the 75th percentile, and it divides approximately 25% of the largest items from the rest of the dataset. In summary, approximately 25% of the items lie between the first and second quartiles, and another 25% lie between the second and third quartiles. \n",
    "\n",
    "<img src=\"images/quartiles.png\" width=\"400\">\n",
    "<em>Figure: Data by quartiles.</em> Source: [6]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, **quantiles** divide the dataset into equal-sized intervals. An example of quantiles are the quartiles. The type of quantiles that divide the dataset into 100 equal parts are called **percentiles**. However, quantiles are often referred to as percentiles. \n",
    "\n",
    "The 10th percentile is the element in the dataset that is less than or equal to 10% of the data. Also, 90% of the elements are greater than or equal to the 10th percentile. If there are two such elements in the dataset, then the 10th percentile is their arithmetic mean.\n",
    "\n",
    "`NumPy` and `pandas` provide functions for calculating quantiles. Examples for calculating 10th and 75th quantiles (percentiles) are shown in the next cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy: 1.6\n",
      "pandas: 1.6\n"
     ]
    }
   ],
   "source": [
    "quantile10th = np.quantile(y, 0.10)\n",
    "print('NumPy:', quantile10th)\n",
    "\n",
    "quantile10th  = z.quantile(0.10)\n",
    "print('pandas:', quantile10th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy: 8.0\n",
      "pandas: 8.0\n"
     ]
    }
   ],
   "source": [
    "quantile75th = np.quantile(y, 0.75)\n",
    "print('NumPy:', quantile75th)\n",
    "\n",
    "quantile75th  = z.quantile(0.75)\n",
    "print('pandas:', quantile75th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `NumPy` there is also a `percentile()` function which expects the argument to be between 0 and 100, whereas the `quantile()` function expects the argument to be between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy: 8.0\n"
     ]
    }
   ],
   "source": [
    "quantile75th = np.percentile(y, 75)\n",
    "print('NumPy:', quantile75th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate IQR, we can first calculate the first and third quartiles (i.e., 25th and 75th percentiles), and afterward take their difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy: 5.5\n",
      "pandas: 5.5\n"
     ]
    }
   ],
   "source": [
    "quartiles = np.quantile(y, [0.25, 0.75])\n",
    "interquartile_range = quartiles[1] - quartiles[0]\n",
    "print('NumPy:', interquartile_range)\n",
    "\n",
    "quartiles = z.quantile([0.25, 0.75])\n",
    "interquartile_range = quartiles[0.75] - quartiles[0.25]\n",
    "print('pandas:', interquartile_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **sample variance** quantifies the spread of the data. It shows numerically how far the data points are from the mean of the dataset. It is calculated as the average of the squared differences from the mean.  We can express the sample variance of a dataset with $ùëõ$ elements mathematically as:\n",
    "\n",
    "$s^2 = \\frac{\\sum_{i=1}^{n} (x_i - \\overline{x})^2}{(n - 1)}$\n",
    "\n",
    "where $\\overline{x}$ is the sample mean. To denote population variance, the notation $\\sigma^2$ is commonly used.\n",
    "\n",
    "We can calculate the variance using the function `statistics.variance()`, in `NumPy` with `np.var()`, and in `pandas` with `.var()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 123.2\n",
      "NumPy: 123.19999999999999\n",
      "pandas: 123.19999999999999\n"
     ]
    }
   ],
   "source": [
    "var = statistics.variance(x)\n",
    "print('Python:', var)\n",
    "\n",
    "var = np.var(y, ddof=1)\n",
    "print('NumPy:', var)\n",
    "\n",
    "var = z.var(ddof=1)\n",
    "print('pandas:', var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `NumPy` and `pandas`, the parameter `ddof=1` sets the *delta degrees of freedom* to 1. This parameter allows the calculation of $s^2$ with $(ùëõ ‚àí 1)$ in the denominator instead of $ùëõ$. By using $(ùëõ ‚àí 1)$ for the variance of a sample, we account for the bias in estimating the population variance, and compensate for the fact that the sample mean is used as an approximation of the true population mean. This adjustment (called Bessel's correction) compensates for the fact that the sample is likely to underestimate the true population variance. To calculate the variance of a population, we can set the *delta degrees of freedom* to 0 in the above codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance quantifies the spread of the data in squared units, which can make the interpretation less intuitive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample **standard deviation** is the positive square root of the sample variance. \n",
    "\n",
    "$s = \\sqrt{\\frac{\\sum_{i=1}^{n} (x_i - \\overline{x})^2}{(n - 1)}}$\n",
    "\n",
    "The standard deviation is often more convenient to work with than the variance, because it has the same unit as the data points.\n",
    "\n",
    "Although we can calculate the standard deviation simply by taking the square root of the variance, almost all libraries have a separate `std()` or `stdev()` function for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 11.099549540409287\n",
      "NumPy: 11.099549540409285\n",
      "pandas: 11.099549540409285\n"
     ]
    }
   ],
   "source": [
    "std = statistics.stdev(x)\n",
    "print('Python:', std )\n",
    "\n",
    "std = np.std(y, ddof=1)\n",
    "print('NumPy:', std)\n",
    "\n",
    "std = z.std(ddof=1)\n",
    "print('pandas:', std )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sample **skewness** measures the asymmetry of a dataset. The figure below illustrates skewness. A dataset is negatively skewed if it tends to have a lot of extremely small values (i.e., the lower tail is longer than the upper tail) and not so many extremely large values (left subfigure). On the other hand, if there are more extremely large values than extremely small ones (right subfigure) we say that the dataset is positively skewed. The formula for the skewness of a dataset is as follows:\n",
    "\n",
    "$\\text{skew} = \\frac{\\sum_{i=1}^{n} (x_i - \\overline{x})^3}{n s^3}$\n",
    "\n",
    "<img src=\"images/skewness.png\" width=\"600\">\n",
    "<em>Figure: Skewness of a sample.</em> Source: [2].</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate skewness by using the method `.skew()` in pandas and `scipy.stats.skew()` can be used with `NumPy` arrays. The parameter `bias=False` in the codes indicates to use the unbiased estimation for a sample variance by applying the correction factor (mentioned in the section on variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy: 1.9470432273905927\n",
      "pandas: 1.9470432273905924\n"
     ]
    }
   ],
   "source": [
    "skew = scipy.stats.skew(y, bias=False)\n",
    "print('NumPy:', skew)\n",
    "\n",
    "skew = z.skew()\n",
    "print('pandas:', skew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.3 Summary of Descriptive Statistics <a id=\"10.1.3-summary-of-descriptive-statistics\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library `SciPy` allows to list descriptive statistics with the function `scipy.stats.describe()`, as shown in the next cell. The value `nobs` refers to the number of observations in the dataset, and the rest of the values are self-explanatory. One statistic that we didn't explain is `kurtosis`, which quantifies the \"pointness\" of a dataset, but it is less frequently used in practice. A dataset that is flat has negative kurtosis, and a dataset that is pointy has positive kurtosis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=5, minmax=(1.0, 28.0), mean=8.7, variance=123.19999999999999, skewness=1.9470432273905927, kurtosis=3.878019618875446)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.describe(y, ddof=1, bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `pandas` we can use the method `describe()` to list descriptive statistics. As we mentioned in the lecture on `pandas`, for a DataFrame `describe()` returns descriptive statistics for all columns in the DataFrame that have numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     5.00000\n",
       "mean      8.70000\n",
       "std      11.09955\n",
       "min       1.00000\n",
       "25%       2.50000\n",
       "50%       4.00000\n",
       "75%       8.00000\n",
       "max      28.00000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1.4 Measures of Correlation <a id=\"10.1.4-measures-of-correlation\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When performing data analysis, we often need to examine and describe the relationship between the values of two variables (features) in a dataset. If the variables are denoted ùë• and ùë¶, we can create pairs of corresponding elements (ùë•‚ÇÅ, ùë¶‚ÇÅ), (ùë•‚ÇÇ, ùë¶‚ÇÇ), and so on, and examine the correlation between the variables. \n",
    "\n",
    "In general, based on the relationship between the pairs of data points, we can identify the following types of correlation:\n",
    "\n",
    "* *Negative correlation*, exists when larger values of ùë• correspond to smaller values of ùë¶ and vice versa (left subfigure).\n",
    "* *Weak or no correlation*, exists if there is no such apparent relationship (middle subfigure).\n",
    "* *Positive correlation*, exists when larger values of ùë• correspond to larger values of ùë¶ and vice versa (right subfigure).\n",
    "\n",
    "<img src=\"images/correlation.png\" width=\"600\">\n",
    "<em>Figure: Correlation between two variables.</em> Source: [1].</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two statistics that measure the correlation between datasets are **covariance** and **correlation coefficient**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **sample covariance** is a measure that quantifies the strength and direction of a relationship between a pair of variables.\n",
    "\n",
    "* If the correlation is positive, the covariance is positive. A stronger relationship corresponds to a higher value of the covariance.\n",
    "* If the correlation is negative, the covariance is negative. A stronger relationship corresponds to a lower value of the covariance.\n",
    "* If the correlation is weak, the covariance is close to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariance of variables ùë• and ùë¶ is mathematically defined as:\n",
    "\n",
    "$s_{xy} = \\frac{\\sum_{i=1}^{n} (x_i - \\overline{x}) (y_i - \\overline{y})}{(n - 1)}$\n",
    "\n",
    "Therefore, the covariance of two identical variables is actually the variance, i.e., $s_{xx} = {\\sum_{i} (x_i - \\overline{x})^2}/{(n - 1)}=(s_{x})^2$. Or, we can say that the covariance is a generalization of the concept of variance to two or more variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show the calculation of the covariance in Python, let's create two variables and convert them to `NumPy` arrays and `pandas` series. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(-10, 11))\n",
    "y = [0, 2, 2, 2, 2, 3, 3, 6, 7, 4, 7, 6, 6, 9, 4, 5, 5, 10, 11, 12, 14]\n",
    "xarr, yarr = np.array(x), np.array(y)\n",
    "xseries, yseries = pd.Series(x), pd.Series(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the two lists. We can notice a positive correlation in the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The covariances between variables are often combined into a **covariance matrix**. For example, to calculate the covariance matrix in `NumPy`, we can use the function `cov()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy: [[38.5        19.95      ]\n",
      " [19.95       13.91428571]]\n"
     ]
    }
   ],
   "source": [
    "cov_matrix = np.cov(xarr, yarr)\n",
    "print('NumPy:', cov_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elements in the covariance matrix are:\n",
    "\n",
    "$\\text{covariance\\_matrix} = \\begin{bmatrix} \n",
    "\\text{cov}(x,x) & \\text{cov}(x,y) \\\\\n",
    "\\text{cov}(y,x) & \\text{cov}(y,y)\n",
    "\\end{bmatrix}$\n",
    "\n",
    "Note that the covariance matrix is symmetric, i.e., the off-diagonal elements `cov(x,y)`$=s_{xy}$ and `cov(y,x)`$=s_{yx}$ are equal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the element `cov(x,y)=19.95` suggests a positive correlation between `x` and `y`, since the values of `y` increase with the increase in the values of `x`.\n",
    "\n",
    "Note in the cell below that the element `cov(x,x)`$=s_{xx}$ is equal to the variance of `x` (that is $s_{x}^2$), and the element `cov(y,y)`$=s_{yy}$ is equal to the variance of `y` (that is $s_{y}^2$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.5\n",
      "13.914285714285711\n"
     ]
    }
   ],
   "source": [
    "print(xarr.var(ddof=1))\n",
    "print(yarr.var(ddof=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `pandas` the method `.cov()` returns the covariance between two Series objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.95"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_xy = xseries.cov(yseries)\n",
    "cov_xy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation Coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **correlation coefficient**, also known as **Pearson correlation coefficient**, is another important measure of correlation. It is commonly denoted by the symbol ùëü, and it is calculated as:\n",
    "\n",
    "$r = \\frac{s_{xy}}{s_{x}s_{y}}$\n",
    "\n",
    "The correlation coefficient is equal to the covariance of the variables $s_{xy}$ divided by the standard deviations of $x$ and $y$. Or, we can say that the correlation coefficient is a measure of standardized covariance. The standardization makes the coefficient in the range from -1 to 1. \n",
    "\n",
    "Examples of variables with different values of the correlation coefficient are shown in the figure below.\n",
    "\n",
    "* The value r = ‚àí1 is the minimum possible value of ùëü, and corresponds to a perfect negative linear relationship between variables.\n",
    "* The value ùëü < 0 indicates negative correlation. The more the data is spread, the weaker the correlation is. \n",
    "* The value r = 0 means that the correlation between the variables is weak.\n",
    "* The value ùëü > 0 indicates positive correlation.\n",
    "\n",
    "The maximum possible value of ùëü is 1, and corresponds to a perfect positive linear relationship between variables.\n",
    "\n",
    "<img src=\"images/PCC.png\" width=\"700\">\n",
    "<em>Figure: Correlation coefficient $r$.</em> Source: [3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the correlation coefficient, we can use `pearsonr()` in `scipy.stats`. It returns both the correlation coefficient and the ùëù-value. In the next cell, the correlation coefficient is 0.86, indicating strong correlation between the variables `x` and `y`. A small ùëù-value indicates that there is statistically significant evidence that there is a linear correlation between the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PearsonRResult(statistic=0.8619500056316061, pvalue=5.122760847201132e-07)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.pearsonr(xarr, yarr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the covariance matrix, in `NumPy` the function `np.corrcoef()` returns the correlation coefficient matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.86195001],\n",
       "       [0.86195001, 1.        ]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_matrix = np.corrcoef(xarr, yarr)\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `pandas`, the method `.corr()` is used for calculating the correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.861950005631606"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xseries.corr(yseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should note that the correlation coefficient measures the strength of the linear relationship between two variables. In other words, it measures the extent to which the data tend to fall on a single, perfectly straight line. \n",
    "\n",
    "If the relationship between two variables is non-linear, then the correlation coefficient is not a suitable measure. For example, in the figure below the variables have sinusoidal or exponential relationship, and the calculation of the correlation coefficient is not meaningful, because the relationship is not linear.\n",
    "\n",
    "<img src=\"images/nonlinear_relationship.png\" width=\"700\">\n",
    "<em>Figure: Nonlinear relationship between variables.</em> Source: [4]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 Inferential Statistics <a id=\"10.2-inferential-statistics\"/>\n",
    "\n",
    "Inferential statistics allow to make predictions or inferences about a population based on a sample of data. Unlike descriptive statistics which simply summarize data, inferential statistics help us draw conclusions and make predictions beyond the immediate data.\n",
    "\n",
    "Common methods of inferential statistics include:\n",
    "\n",
    "* Regression analysis, models relationships between variables to make predictions or understand relationships.\n",
    "* Estimation methods, infer the values of population parameters based on sample data.\n",
    "* Confidence intervals, provide a range within which a population parameter is expected to lie with a certain level of confidence.\n",
    "* Hypothesis testing, tests hypotheses about population parameters using statistical tests (e.g., t-tests, chi-square tests, ANOVA (Analayis of Variance))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.1 Linear Regression <a id=\"10.2.1-linear-regression\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concept of linear regression has similarities to the Pearson correlation coefficient, as the goal is to examine whether there is a linear relationship between variables. However, regression models are more powerful tools than the measures of correlation. \n",
    "\n",
    "Given two sets of observations `x` and `y`, a **linear regression** model returns a regression line:\n",
    "\n",
    "$\\hat{y_i} = b_0 + b_1x_i$\n",
    "\n",
    "The values $b_0$ and $b_1$ are *regression coefficients* and represent the intercept of the regression line with the y-axis and the slope of the line, respectively. The regression coefficients are also called the *weights* of the regression model. \n",
    "\n",
    "A linear regression model estimates the values of the regression coefficients $b_0$ and $b_1$ for a given dataset. The objective is to find the set of regression coefficients so that for all data $x_i$, the obtained values from the regression equation for the variable $\\hat{y_i}$ are as close as possible to the actual values $y_i$. The variable `x` is called independent variable, or it is also called input variable, or observed variable. The variable `y` is called dependent variable, or predicted variable, or target variable, since the objective is to predict the values of `y` for given observations `x`.\n",
    "\n",
    "One common approach for calculating the regression coefficients is by minimizing the sum of the squared differences between the predicted values $\\hat{y_i}$ and actual values $y_i$, i.e., $\\sum_{i} (\\hat{y_i}-y_i)^2$ for $ùëñ = 1, 2, ‚Ä¶, ùëõ$. This approach is called the method of *ordinary least squares*. The differences between the predicted values $\\hat{y_i}$ and actual values $y_i$ are also referred to as *residuals*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `scipy` we can use the function `scipy.stats.linregress` to  perform linear regression. The result is shown below, and as we can see, the returned values are the slope and intercept of the regression line, `rvalue` is the correlation coefficient, `pvalue` is the probability of the linear relationship between the variables, and `stderr` and `intercept_stderr` are standard deviations associated with the uncertainties in estimating the slope and intercept of the regression line, respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinregressResult(slope=0.5181818181818181, intercept=5.714285714285714, rvalue=0.8619500056316057, pvalue=5.122760847201238e-07, stderr=0.06992387660074986, intercept_stderr=0.42341009950025926)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.stats.linregress(xarr, yarr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To access specific values from the result of `scipy.stats.linregress()`, we can use the dot notation, as in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5181818181818181 5.714285714285714 0.8619500056316057\n"
     ]
    }
   ],
   "source": [
    "result = scipy.stats.linregress(xarr, yarr)\n",
    "print(result.slope, result. intercept, result.rvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another library for perfroming linear regression is `scikit-learn`, which we will use extensively later in this course. To quickly demonstrate linear regression, in the next cell we imported the model `LinearRegression()`, and used the method `fit()` to apply a linear regression model to the data. For this example we introduced new data variables, where the independent variable is `hours` and refers to the hours of study for an exam, and the dependent variable is `marks` representing the obtained score from the exam.  We assume that there is a linear relationship between the hours of the study and the exam marks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hours = np.array([1, 2, 3, 4, 5])\n",
    "marks = np.array([52, 54, 61, 68, 72])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"‚ñ∏\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"‚ñæ\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LinearRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LinearRegression.html\">?<span>Documentation for LinearRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LinearRegression()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(hours.reshape((-1, 1)), marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the slope and intercept regression coefficients of the model through the attributes `coef_` and `intercept_` of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.4] 45.2\n"
     ]
    }
   ],
   "source": [
    "print(model.coef_, model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the linear regression model $\\hat{y_i} = b_0 + b_1x_i$ to make predictions for the `marks` based on given values `hours` in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "marks_pred = model.intercept_ + model.coef_ * hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cell, we plotted the actual data with blue markers and the obtained regression line with red color. The intercept with the y-axis is not shown in the plot, but we can notice that for `marks=0` the intercept would be around 45 as obtained in the previous cell. I.e., if the student studies 0 hours, the expected score is 45 marks. The slope of the regrestion line is 5.4, meaning that for each additional hour of study, the exam score is expected to increase by about 5.4 marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(hours, marks, color='blue', label='Actual data')\n",
    "plt.plot(hours, marks_pred, color='red', label='Regression line')\n",
    "plt.xlabel('hours')\n",
    "plt.ylabel('marks')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The linear regression model in `scikit-learn` can also be applied to `pandas` DataFrames, besides `NnmPy` arrays.\n",
    "\n",
    "We will learn more about regression models in the subsequent lectures in this course. Here we covered an example of linear regression with one dependent and one independent variable, which is also referred to as *simple linear regression*, and is an example of a **univariate regression**. It is possible to consider multiple independent variables (e.g., using multiple input features) to predict another variable, referred to as **multiple regression**. And the problem of predicting the value of multiple dependent variables is called **multivariate regression**.\n",
    "\n",
    "Besides linear regression models which fit a line to a dataset, there are numerous non-linear regression models that fit a non-linear model to a dataset. Later in the course we will study non-linear regression models, such as Random Forest regression model, Support Vector regression model, Neural Networks, and other models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2.1.1 Evaluating the Fit of a Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commonly used metrics for evaluating if the regression model is a good fit to a dataset are:\n",
    "\n",
    "* $R$-Squared value (coefficient of determination)\n",
    "* Mean Squared Error (MSE)\n",
    "* Root Mean Squared Error (RMSE)\n",
    "* Mean Absolute Error (MAE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10.2.1.2 $R$-Squared Value (Coefficient of Determination)\n",
    "\n",
    "**$R$-squared** value or **$R^2$** is also known as the **coefficient of determination**. R-Squared measures how well the independent variable (e.g., `hours`) explains the variability of the dependent (predicted) variable (`marks`, in this case). Its value ranges from 0 to 1, where 0 means that the variance in the predicted variable is not explained by the model, and indicates a poor regression fit. Conversely, 1 means that the variance in the predicted variable is well explained by the model, and indicates a good fit where the predicted exam marks are close to the actual values of the exam marks.\n",
    "\n",
    "The coefficient of determination is calculated as: \n",
    "\n",
    "$R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}= 1 - \\frac{RSS}{TSS}$\n",
    "\n",
    "The term in the numerator is called Residual Sum of Squares (RSS), and it is the sum of the squared differences for the residuals, i.e., between each actual value and the corresponding predicted value. It measures the variance that is not explained by the model. The term in the denominator is called Total Sum of Squares (TSS), and it is the sum of the squared differences between each actual value and the mean of the actual values. It measures the total variance in the dependent variable (exam marks). Overall, the R-squared equation measures the proportion of variance in the dependent variable (exam marks) that is predictable from the independent variable (hours) in a regression model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate $R$-Squared, we can import `r2_score` from `scikit-learn`, and apply it by using the actual and the predicted values by a model. In this case, the value is 0.97, which means that 97% of the variance in the variable `marks` is explained by the `hours` studied. This suggests that the regression model is quite effective in predicting the exam marks based on the hours studied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9745989304812834\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2 = r2_score(marks, marks_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a simple linear regression with one independent variable, $R$-Squared is equal to the squared value of the Pearson correlation coefficient, i.e., $R^2=r^2$. Recall again that the correlation coefficient measures the strength and direction of the linear relationship between two variables, and it ranges from -1 to 1. $R$-Squared measures how well a regression model explains the variability in the predicted variable, and it ranges from 0 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10.2.1.3 Mean Squared Error (MSE) and Root Mean Squared Error (RMSE)\n",
    "\n",
    "**Mean Squared Error (MSE)** is calculated as the average of the squared differences between the actual and predicted values. \n",
    "\n",
    "$\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$\n",
    "\n",
    "**Root Mean Squared Error (MSE)** is the square root of MSE. An advantage of RMSE in comparison to MSE is that it represents the error in the same units as the target variable.\n",
    "\n",
    "$\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSE can be calculated by importing `mean_squared_error` from `scikit-learn`, and RMSE then is calculated as the square root of MSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5200000000000016\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(marks, marks_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.232882800593796\n"
     ]
    }
   ],
   "source": [
    "rmse = mse ** 0.5\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10.2.1.4 Mean Absolute Error (MAE)\n",
    "\n",
    "**Mean Absolute Error (MAE)** is calculated as the average of the absolute differences between the actual and predicted values. It quantifies how far predictions are from the true values.\n",
    "\n",
    "$\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_i - \\hat{y}_i|$\n",
    "\n",
    "MAE can also be imported from `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.040000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "mae = mean_absolute_error(marks, marks_pred)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smaller values of MSE, RMSE, and MAE are indicators of a better regression fit, and greater values of $R$-squared represent a better regression fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.2 Standard Error of the Mean <a id=\"10.2.2-standard-error-of-the-mean\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **standard error** estimates the variability of a sample statistic from the true population parameter. A commonly used standard error measure is for the sample mean. \n",
    "\n",
    "The **standard error of the mean (SEM)** is an inferential statistic that measures the variability of the sample mean as an estimate of the true population mean. It is often used in estimation methods, confidence intervals, and hypothesis testing.\n",
    "\n",
    "The SEM is the standard deviation of the sampling distribution of the sample mean. It quantifies how much the sample mean is expected to fluctuate from the true population mean if we repeatedly draw new samples from the population. \n",
    "\n",
    "To calculate SEM, we use the following formula:\n",
    "\n",
    "$\\text{SEM} = \\frac{\\sigma}{\\sqrt{n}}$\n",
    "\n",
    "In the formula, $\\sigma$ is the population standard deviation and $ùëõ$ is the sample size. If the population standard deviation is unknown, the sample standard deviation $s$ is used.\n",
    " \n",
    "The SEM provides insight into the reliability of the sample mean as an estimate of the population mean. A smaller SEM indicates a more precise estimate, which is valuable for making statistical inferences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, we can calculate the standard error of the mean via the `sem()` function in `scipy.stats`. Large value of the standard error of the mean indicates more spread out values around the mean of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0014468450808804"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [3, 4, 4, 5, 7, 8, 12, 14, 14, 15, 17, 19, 22, 24, 24, 24, 25, 28, 28, 29]\n",
    "\n",
    "scipy.stats.sem(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.3"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the standard error of the mean depends on the sample size $n$, as the sample size increases, the standard error of the mean tends to decrease."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.3 Confidence Intervals <a id=\"10.2.3-confidence-intervals\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A **confidence interval** is a range of values derived from sample data and used to estimate the true population parameter. The **confidence level** represents the degree of uncertainty associated with the estimate. For example, a 90% confidence level means that if the same sampling process is repeated multiple times, the true population mean would fall within the upper and lower values of the confidence interval 90 out of 100 times.\n",
    "\n",
    "The confidence interval (CI) is calculated with the following formula.\n",
    "\n",
    "$\\text{CI} = \\bar{x} \\pm Z \\cdot \\frac{\\sigma}{\\sqrt{n}}$\n",
    "\n",
    "In the formula, $\\bar{x}$ is the sample mean, $\\sigma$ is the population standard deviation, $n$ is the sample size, and $Z$ is the Z-score corresponding to the desired confidence level. Notice that the CI depends on the standard error of the mean ($\\text{SEM} = {\\sigma}/{\\sqrt{n}}$), and it can be written as $\\text{CI} = \\bar{x} \\pm Z \\cdot \\text{SEM}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Z-score** is a statistical measure that quantifies how many standard deviations a data point is from the mean of a distribution. It is a method for standardizing scores on a normal distribution. For a given value $x$ in a dataset with mean $\\bar{x}$ and standard deviation $\\sigma$, the Z-score is calculated as:\n",
    "\n",
    "$Z = \\frac{x - \\bar{x}}{\\sigma}$\n",
    "\n",
    "Example of Z-scores for Confidence Intervals:\n",
    "\n",
    "* 95% Confidence Interval: the Z-score corresponds to the critical value that leaves 2.5% in each tail of the normal distribution. The Z-score for a 95% confidence interval is approximately ¬±1.96. The figure below depicts the 95% confidence interval for the sample mean. \n",
    "* 99% Confidence Interval: the Z-score corresponds to the critical value that leaves 0.5% in each tail of the normal distribution. The Z-score for a 99% confidence interval is approximately ¬±2.58.\n",
    "\n",
    "<img src=\"images/CIDiagram.png\" width=\"400\">\n",
    "<em>Figure: 95% confidence interval.</em>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All statistical software packages provide Z-scores for a desired confidence level. Additionally, Z-scores can be read from normal distribution tables, also called Z-tables. For example, to find the Z-score for a 95% confidence level, we need to locate the value in the table that leaves 2.5% in each tail, which corresponds to ¬±1.96.\n",
    "\n",
    "In the next example, we first draw 100 samples from a random uniform distribution having integer values between 5 and 10. Next, we calculate the sample mean and the standard error of the mean. Afterward, we use the `norm.interval()` function from `scipy.stats` to calculate the confidence interval. Arguments in the function are the confidence interval (set to 90%), the sample mean, and the standard error of the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = np.random.randint(5, 10, 100) \n",
    "\n",
    "# sample mean\n",
    "sample_mean = np.mean(sample_data)\n",
    "# standard error of the mean\n",
    "sample_sem = scipy.stats.sem(sample_data)\n",
    "\n",
    "# 90% confidence interval for population mean \n",
    "confidence_interval = scipy.stats.norm.interval(confidence=0.90, loc=sample_mean, scale=sample_sem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, the sample mean is 6.77, and the 90% confidence interval is from 6.55 to 6.99."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.76\n",
      "(6.54178550737387, 6.97821449262613)\n"
     ]
    }
   ],
   "source": [
    "print(sample_mean)\n",
    "print(confidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we set the confidence level to 99%, that is, we want to be 99% sure the interval contains the true population mean. The resulting CI is between 6.39 and 7.15, and it is a wider interval because we are trying to capture the true mean with greater certainty, accounting for more possible variation in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.76\n",
      "(6.4182776270450335, 7.101722372954966)\n"
     ]
    }
   ],
   "source": [
    "# 99% confidence interval for population mean \n",
    "confidence_interval = scipy.stats.norm.interval(confidence=0.99, loc=sample_mean, scale=sample_sem)\n",
    "\n",
    "print(sample_mean)\n",
    "print(confidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the population standard deviation $\\sigma\\$ is unknown, we can use the sample standard deviation to calculate the CI using the following formula:\n",
    "\n",
    "$\\text{CI} = \\bar{x} \\pm t \\cdot \\frac{s}{\\sqrt{n}}$\n",
    "\n",
    "In this case, a $t$-score from the $t$-distribution is used that corresponds to the desired confidence level.\n",
    "\n",
    "Additionally, if the sample size is small and it is below 30 data points, the above formula based on $t$-score is used for calculating the CI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a smaller dataset containing 16 data points first. We can calculate the confidence interval by using the `t.interval()` function from `scipy.stats`. The rest of the code is similar to the above cell, with the only difference that there is one additional parameter corresponding to the degree of freedom of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = [1, 1, 1, 2, 2, 3, 3, 3, 4, 4, 5, 5, 6, 7, 8, 10] \n",
    "\n",
    "# sample mean\n",
    "sample_mean = np.mean(sample_data)\n",
    "# standard error of the mean\n",
    "sample_sem = scipy.stats.sem(sample_data)\n",
    "# degrees of freedome\n",
    "sample_df = len(sample_data)-1\n",
    "  \n",
    "# create 90% confidence interval \n",
    "confidence_interval = scipy.stats.t.interval(confidence=0.90, loc=sample_mean, scale=sample_sem, df=sample_df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0625\n",
      "(2.903311331486366, 5.221688668513634)\n"
     ]
    }
   ],
   "source": [
    "print(sample_mean)\n",
    "print(confidence_interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2.4 Hypothesis Testing <a id=\"10.2.4-hypothesis-testing\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hypothesis testing is a fundamental statistical technique for making inferences about populations based on sample data. \n",
    "\n",
    "Hypothesis testing involves two main hypotheses:\n",
    "\n",
    "* Null Hypothesis ($H_0$): it is the default hypothesis that any observed changes are due to random chance. It serves as the baseline against which the alternative hypothesis is tested. For example, in a drug efficacy test, the null hypothesis can be \"The drug has no effect on patients.\"\n",
    "* Alternative Hypothesis ($H_1$, or $H_a$): it is the opposite of the null hypothesis and suggests that there is an effect or a difference, and the observed changes are not due to random chance. For the example with the drug test, the alternative hypothesis can be \"The drug has a significant effect on patients.\"\n",
    "\n",
    "In hypothesis testing, a low $p$-value (typically less than a significance level $\\alpha$, such as 0.05) results in rejecting the null hypothesis, suggesting that the alternative hypothesis may be true. Conversely, a high $p$-value indicates that the observed data is consistent with the null hypothesis, and there is insufficient evidence to reject the null hypothesis. \n",
    "\n",
    "Several types of hypothesis tests are used depending on the given data and research question. Following are common hypothesis tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**One-Sample t-Test**\n",
    "\n",
    "One-sample $t$-test is used to determine whether the mean of a sample is significantly different from a known value.\n",
    "\n",
    "The $t$-statistic is calculated as:\n",
    "\n",
    "$t = \\frac{\\bar{x} - \\mu_0}{\\frac{s}{\\sqrt{n}}}$\n",
    "\n",
    "where $\\bar{x}$ is the sample mean, $\\mu_0$ is the population mean under the null hypothesis, $s$ is the sample standard deviation, and $n$ is the sample size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4940357616679902 0.19539449179127277\n",
      "Fail to reject the null hypothesis\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "data = np.array([2.3, 2.8, 2.5, 2.7, 3.1, 2.6])\n",
    "\n",
    "# Null hypothesis: mean = 2.5\n",
    "t_statistic, p_value = scipy.stats.ttest_1samp(data, 2.5)\n",
    "\n",
    "print(t_statistic, p_value)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.6666666666666665"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the $p$-value is greater than 0.05, we fail to reject the null hypothesis that the mean of `data` is 2.5, meaning there is no significant difference from 2.5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Two-Sample t-Test**\n",
    "\n",
    "This test is used to compare the means of two independent samples.\n",
    "\n",
    "The $t$-statistic is calculated as:\n",
    "\n",
    "$t = \\frac{\\bar{x}_1 - \\bar{x}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}$\n",
    "\n",
    "where $\\bar{x}_1$ and $\\bar{x}_1$ are the sample means, $s_1$ and  $s_2$ are the standard deviations, and $n_1$ and $n_2$ are the sample sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.302287394737564 8.882097195524333e-05\n",
      "Reject the null hypothesis\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "data1 = np.array([2.3, 2.8, 2.5, 2.7, 3.1, 2.6])\n",
    "data2 = np.array([3.2, 3.5, 3.6, 3.7, 3.8, 3.9])\n",
    "\n",
    "# Null hypothesis: means of data1 and data2 are equal\n",
    "t_statistic, p_value = scipy.stats.ttest_ind(data1, data2)\n",
    "\n",
    "print(t_statistic, p_value)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the $p$-value is less than 0.05, we reject the null hypothesis that the means of `data1` and `data2` are equal, and we conclude that the two sample means are significantly different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paired t-Test**\n",
    "\n",
    "Paired $t$-test is used to compare the means of two related groups. For instance, when we have two measurements taken on the same sample or matched pairs before and after an intervention or change.\n",
    "\n",
    "The $t$-statistic is calculated as:\n",
    "\n",
    "$t = \\frac{\\bar{d}}{\\frac{s_d}{\\sqrt{n}}}$\n",
    "\n",
    "where $\\bar{d}$ is the mean difference between paired observations, $s_d$ is the standard deviation of the differences, and $n$ is the number of pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.9999999999999885 0.0009167475143984109\n",
      "Reject the null hypothesis\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "before = np.array([2.3, 2.8, 2.5, 2.7, 3.1, 2.6])\n",
    "after = np.array([2.4, 2.9, 2.7, 2.8, 3.2, 2.7])\n",
    "\n",
    "# Null hypothesis: means of before and after are equal\n",
    "t_statistic, p_value = scipy.stats.ttest_rel(before, after)\n",
    "\n",
    "print(t_statistic, p_value)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is less than 0.05, therefore we reject the null hypothesis that the means are equal, and we conclude that the difference between the means before and after the intervention is statistically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chi-Square Test**\n",
    "\n",
    "Chi-square test is used for categorical data to assess how likely it is that an observed distribution is due to chance.\n",
    "\n",
    "The test statistic is calculated as:\n",
    "\n",
    "$\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}$\n",
    "\n",
    "where $O_i$ are the observed frequencies, and $E_i$ are the expected frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0 0.00016974243555282632\n",
      "Reject the null hypothesis\n"
     ]
    }
   ],
   "source": [
    "# Observed frequencies\n",
    "observed = np.array([30, 10, 20, 40])\n",
    "\n",
    "# Expected frequencies\n",
    "expected = np.array([25, 25, 25, 25])\n",
    "\n",
    "# Null hypothesis: observed and expected frequencies are equal\n",
    "chi2_statistic, p_value = scipy.stats.chisquare(observed, expected)\n",
    "\n",
    "print(chi2_statistic, p_value)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $p$-value is less than 0.05, therefore we reject the null hypothesis, and conclude that the observed frequencies differ significantly from the expected ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References <a id=\"references\"/>\n",
    "\n",
    "1. Python Statistics Fundamentals: How to Describe Your Data, by Mirko Stojiljkoviƒá, available at: [https://realpython.com/python-statistics/](https://realpython.com/python-statistics/).\n",
    "2. Learning Statistics with Python, by Ethan Weed, available at: [https://ethanweed.github.io/pythonbook/landingpage.html#](https://ethanweed.github.io/pythonbook/landingpage.html#).\n",
    "3. Correlation Coefficients: Appropriate Use and Interpretation, by Patrick Schober, Christa Boer, and Lothar A Schwarte, available at: [https://pubmed.ncbi.nlm.nih.gov/29481436/](https://pubmed.ncbi.nlm.nih.gov/29481436/)\n",
    "4. Linear and Nonlinear Correlations, available at: [https://rovusa.com/quantitative-statistical-methods-and-data-science/linear-and-nonlinear-correlations/](https://rovusa.com/quantitative-statistical-methods-and-data-science/linear-and-nonlinear-correlations/).\n",
    "5. Mastering Statistical Analysis in Python with Real-World Datasets, by Ratan Kumar Sajja, available at: [https://python.plainenglish.io/mastering-statistical-analysis-in-python-with-real-world-datasets-d5b60e541189](https://python.plainenglish.io/mastering-statistical-analysis-in-python-with-real-world-datasets-d5b60e541189).\n",
    "6. Applying Descriptive and Inferential Statistics in Python, by Cornellius Yudha Wijaya, available at: [https://www.kdnuggets.com/applying-descriptive-and-inferential-statistics-in-python](https://www.kdnuggets.com/applying-descriptive-and-inferential-statistics-in-python). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[BACK TO TOP](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
