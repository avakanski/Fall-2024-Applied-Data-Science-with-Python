{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0cd5d005-15fe-42a5-ad59-154b9dbb841f",
   "metadata": {},
   "source": [
    "# Tutorial 8 - TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b0a8de-8a5b-4d05-9f11-8ae89ebbbc77",
   "metadata": {},
   "source": [
    "[![View notebook on Github](https://img.shields.io/static/v1.svg?logo=github&label=Repo&message=View%20On%20Github&color=lightgrey)](https://github.com/avakanski/Fall-2023-Python-Programming-for-Data-Science/blob/main/docs/Lectures/Theme_3-Model_Engineering/Tutorial_8-TensorFlow/Tutorial_8-TensorFlow.ipynb)\n",
    "[![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/avakanski/Fall-2023-Python-Programming-for-Data-Science/blob/main/docs/Lectures/Theme_3-Model_Engineering/Tutorial_8-TensorFlow/Tutorial_8-TensorFlow.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537e13f4-f622-4766-a5d8-1d0d4fdc17ce",
   "metadata": {},
   "source": [
    "<a id='top'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6607f8f5",
   "metadata": {},
   "source": [
    "This tutorial is adapted from a 2022 blog post on the website [Made With ML](https://madewithml.com/), by Goku Mohandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61624c49-1bd8-44c1-a41e-740d03aa3c19",
   "metadata": {},
   "source": [
    "We will import `TensorFlow` and `numpy` and set the seed for their random number generators for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ff53b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version: 2.14.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "\n",
    "\n",
    "print(f'TF version: {tf.__version__ }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1384dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d7ae361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducability\n",
    "np.random.seed(seed=SEED)\n",
    "tf.random.set_seed(seed=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a1465c",
   "metadata": {},
   "source": [
    "## TensorFlow Basics\n",
    "\n",
    "First, we will cover some basics such as creating TensorFlow tensors and converting from common data structures to TensorFlow tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ffa9665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type: <dtype: 'float32'>\n",
      "shape: (2, 3)\n",
      "values:\n",
      "[[-1.1012203   1.5457517   0.383644  ]\n",
      " [-0.87965786 -1.2246722  -0.9811211 ]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.normal((2, 3))\n",
    "print(f'Type: {x.dtype}')\n",
    "print(f'shape: {x.shape}')\n",
    "print(f'values:\\n{x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fabb7cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]], shape=(2, 3), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Zeros and ones tensors\n",
    "x = tf.zeros((2, 3), dtype=tf.float64)\n",
    "print(x)\n",
    "x = tf.ones((2, 3))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a8b46a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3)\n",
      "values:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "# List => Tensor\n",
    "x = tf.constant([[1, 2, 3], \n",
    "                  [4, 5, 6]])\n",
    "\n",
    "print(f'shape: {x.shape}')\n",
    "print(f'values:\\n{x}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "473d17c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3)\n",
      "values:\n",
      "[[4.17022005e-01 7.20324493e-01 1.14374817e-04]\n",
      " [3.02332573e-01 1.46755891e-01 9.23385948e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Numpy array => Tensor\n",
    "x = tf.constant(np.random.rand(2, 3))\n",
    "print(f'shape: {x.shape}')\n",
    "print(f'values:\\n{x}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32036e4f",
   "metadata": {},
   "source": [
    "### Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "959f09ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3)\n",
      "values:\n",
      "[[-0.05392435 -1.4948881   0.6654824 ]\n",
      " [ 0.4435789   1.0243716   0.5050061 ]]\n"
     ]
    }
   ],
   "source": [
    "# Addition\n",
    "x = tf.random.normal((2, 3))\n",
    "y = tf.random.normal((2, 3))\n",
    "z = x + y\n",
    "print(f'shape: {z.shape}')\n",
    "print(f'values:\\n{z}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36140745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 2)\n",
      "values:\n",
      "[[ 2.04325     1.1587756 ]\n",
      " [-1.8957058  -0.67201185]]\n"
     ]
    }
   ],
   "source": [
    "# Dot product\n",
    "x = tf.random.normal((2, 3))\n",
    "y = tf.random.normal((3, 2))\n",
    "z = tf.matmul(x, y)\n",
    "print(f'shape: {z.shape}')\n",
    "print(f'values:\\n{z}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fefd133b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3)\n",
      "values: \n",
      "[[-1.1771783  -0.90325946  0.8419609 ]\n",
      " [-0.06870949 -0.96161884 -0.51533026]]\n",
      "shape: (3, 2)\n",
      "values: \n",
      "[[-1.1771783  -0.06870949]\n",
      " [-0.90325946 -0.96161884]\n",
      " [ 0.8419609  -0.51533026]]\n"
     ]
    }
   ],
   "source": [
    "# Transpose\n",
    "x = tf.random.normal((2, 3))\n",
    "print(f\"shape: {x.shape}\")\n",
    "print(f\"values: \\n{x}\")\n",
    "y = tf.transpose(x)\n",
    "print(f\"shape: {y.shape}\")\n",
    "print(f\"values: \\n{y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "729b4e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3, 2)\n",
      "values: \n",
      "[[-0.00839665  0.12513153]\n",
      " [-1.0209956   0.28299028]\n",
      " [-1.8376423   1.1970675 ]]\n"
     ]
    }
   ],
   "source": [
    "# Reshape\n",
    "x = tf.random.normal((2, 3))\n",
    "z = tf.reshape(x, (3, 2))\n",
    "print(f\"shape: {z.shape}\")\n",
    "print(f\"values: \\n{z}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1159fd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3, 4)\n",
      "x: \n",
      "[[[ 1  1  1  1]\n",
      "  [ 2  2  2  2]\n",
      "  [ 3  3  3  3]]\n",
      "\n",
      " [[10 10 10 10]\n",
      "  [20 20 20 20]\n",
      "  [30 30 30 30]]]\n",
      "\n",
      "\n",
      "shape: (3, 8)\n",
      "a: \n",
      "[[ 1  1  1  1  2  2  2  2]\n",
      " [ 3  3  3  3 10 10 10 10]\n",
      " [20 20 20 20 30 30 30 30]]\n",
      "\n",
      "\n",
      "shape: (3, 2, 4)\n",
      "b: \n",
      "[[[ 1  1  1  1]\n",
      "  [10 10 10 10]]\n",
      "\n",
      " [[ 2  2  2  2]\n",
      "  [20 20 20 20]]\n",
      "\n",
      " [[ 3  3  3  3]\n",
      "  [30 30 30 30]]]\n",
      "\n",
      "\n",
      "shape: (3, 8)\n",
      "c: \n",
      "[[ 1  1  1  1 10 10 10 10]\n",
      " [ 2  2  2  2 20 20 20 20]\n",
      " [ 3  3  3  3 30 30 30 30]]\n"
     ]
    }
   ],
   "source": [
    "# Dangers of reshaping (unintended consequences)\n",
    "x = tf.constant([\n",
    "    [[1,1,1,1], [2,2,2,2], [3,3,3,3]],\n",
    "    [[10,10,10,10], [20,20,20,20], [30,30,30,30]]\n",
    "])\n",
    "print(f\"shape: {x.shape}\")\n",
    "print(f\"x: \\n{x}\\n\")\n",
    "\n",
    "a = tf.reshape(x, (x.shape[1], -1))\n",
    "print(f\"\\nshape: {a.shape}\")\n",
    "print(f\"a: \\n{a}\\n\")\n",
    "\n",
    "b = tf.transpose(x, perm=[1, 0, 2])\n",
    "print(f\"\\nshape: {b.shape}\")\n",
    "print(f\"b: \\n{b}\\n\")\n",
    "\n",
    "c = tf.reshape(b, (b.shape[0], -1))\n",
    "print(f\"\\nshape: {c.shape}\")\n",
    "print(f\"c: \\n{c}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf410eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values: \n",
      "[[-0.35975078  1.5145855   0.9998955 ]\n",
      " [-0.83270323  0.10627943 -1.6242576 ]]\n",
      "values: \n",
      "[-1.192454    1.6208649  -0.62436205]\n",
      "values: \n",
      "[ 2.1547303 -2.3506813]\n"
     ]
    }
   ],
   "source": [
    "# Dimensional operations\n",
    "x = tf.random.normal((2, 3))\n",
    "print(f\"values: \\n{x}\")\n",
    "y = tf.reduce_sum(x, axis=0) # sum over columns\n",
    "print(f\"values: \\n{y}\")\n",
    "z = tf.reduce_sum(x, axis=1) # sum over rows\n",
    "print(f\"values: \\n{z}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba97c86e",
   "metadata": {},
   "source": [
    "### Indexing\n",
    "\n",
    "Now we will look at how to extract, separate, and join values from tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f988ade1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: \n",
      "[[ 0.9868413   0.57056284  0.17946035  0.83900064]\n",
      " [ 1.0045967  -0.0642297  -0.6155826  -0.24785912]\n",
      " [-1.4076422   0.27217543  0.5191802   0.97026527]]\n",
      "\n",
      "x[:1]: \n",
      "[0.9868413  0.57056284 0.17946035 0.83900064]\n",
      "\n",
      "x[:1, 1:3]: \n",
      "[[0.57056284 0.17946035]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.normal((3, 4))\n",
    "print (f\"x: \\n{x}\")\n",
    "print()\n",
    "print(f\"x[:1]: \\n{x[0]}\")\n",
    "print()\n",
    "print(f\"x[:1, 1:3]: \\n{x[:1, 1:3]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eba1f45",
   "metadata": {},
   "source": [
    "### Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "173e9430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "values: \n",
      "[[-0.39749852  1.0979848   1.7348342 ]\n",
      " [-0.10556055  0.9014524   0.52277493]]\n",
      "values: \n",
      "[[-0.39749852  1.7348342 ]\n",
      " [-0.10556055  0.52277493]]\n",
      "values: \n",
      "[1.0979848 1.7348342]\n"
     ]
    }
   ],
   "source": [
    "# Select with dimensional indices\n",
    "x = tf.random.normal((2, 3))\n",
    "print(f\"values: \\n{x}\")\n",
    "\n",
    "col_indices = tf.constant([0, 2])\n",
    "chosen = tf.gather(x, axis=1, indices=col_indices) # values from column 0 & 2\n",
    "print(f\"values: \\n{chosen}\")\n",
    "\n",
    "row_indices = tf.constant([0, 1])\n",
    "col_indices = tf.constant([0, 2])\n",
    "chosen = tf.gather_nd(x, indices=[row_indices, col_indices]) # values from (0, 0) & (1, 2)\n",
    "print(f\"values: \\n{chosen}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd08774",
   "metadata": {},
   "source": [
    "### Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7df7b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values: \n",
      "[[-1.87371     0.2745974  -0.03640426]\n",
      " [-0.50639224 -0.20166533 -0.7770617 ]]\n",
      "Values: \n",
      "[[-1.87371     0.2745974  -0.03640426]\n",
      " [-0.50639224 -0.20166533 -0.7770617 ]\n",
      " [-1.87371     0.2745974  -0.03640426]\n",
      " [-0.50639224 -0.20166533 -0.7770617 ]]\n"
     ]
    }
   ],
   "source": [
    "# Concatenation\n",
    "x = tf.random.normal((2, 3))\n",
    "print(f\"Values: \\n{x}\")\n",
    "y = tf.concat([x, x], axis=0) # stack by rows (dim=1 to stack by columns)\n",
    "print(f\"Values: \\n{y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b3df83",
   "metadata": {},
   "source": [
    "### Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da6beda",
   "metadata": {},
   "source": [
    "* $y = 3x + 2$\n",
    "* $z = \\sum{y}/N$\n",
    "* $\\frac{\\partial(z)}{\\partial(x)} = \\frac{\\partial(z)}{\\partial(y)} \\frac{\\partial(y)}{\\partial(x)} = \\frac{1}{N} * 3 = \\frac{1}{12} * 3 = 0.25$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b339ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]\n",
      " [0.25 0.25 0.25 0.25]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Tensors with gradient book keeping\n",
    "x = tf.random.normal((3, 4))\n",
    "\n",
    "# Tensorflow needs graph context to track gradients\n",
    "with tf.GradientTape() as g:\n",
    "    g.watch(x)\n",
    "    y = 3*x + 2\n",
    "    z = tf.reduce_mean(y)\n",
    "\n",
    "dz_dx = g.gradient(z, x)\n",
    "\n",
    "print(dz_dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79797d8",
   "metadata": {},
   "source": [
    "### CUDA\n",
    "\n",
    "This section details how to check if we are able to use GPU to accelerate our machine learning or deep learning models.\n",
    "\n",
    "The Compute Unified Device Architecture or **CUDA** is a parallel computing platform and API that allows software to use certain types of GPUs for general purpose processing. It is an extension of the C and C++ programming languages.\n",
    "\n",
    "`TensorFlow` makes using the GPU quite transparent. If the GPU compatible version of TF is installed along with the proper drivers, TF will use the GPU.\n",
    "\n",
    "Although training is usually faster on the GPU, depending on model size and hardware specs, it can take quite a while to copy the model and your data to the GPU.  \n",
    "\n",
    "[Link](https://anaconda.org/anaconda/tensorflow-gpu) to metapackage for easily installing `TensorFlow` GPU using a conda 'metapackage'. This is just a special package which installs the required GPU drivers alongside TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b971d492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Is CUDA available?\n",
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72b497b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device to first gpu (if available)\n",
    "device = \"/gpu:0\" if tf.test.is_built_with_cuda() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36725788",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(device):\n",
    "    a = tf.constant([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5776a3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 7120276819793909368\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print info about local cpu/gpu devices through tensorflow library\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "# The most useful information is found in the first two lines of the output.\n",
    "# 1st line is name of device (cpu/gpu and number). \n",
    "# If there were 2 cpus on the device, there would be another entry in the list under name: '/device:cpu:1'\n",
    "# The second line give the memory limit in bits. \n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebec5b90",
   "metadata": {},
   "source": [
    "## Tensorflow Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd1bfcb",
   "metadata": {},
   "source": [
    "Public datasets are an important resource for accelerating machine learning research. However, writing custom scripts to fetch and prepare each dataset individually can be tedious. \n",
    "\n",
    "**TensorFlow DataSets (TFDS)** handles the tasks of sourcing the data and standardizing it into a consistent format. Furthermore, TFDS utilizes the `tensorflow.data API` to construct high-performance input pipelines that are seamlessly usable with tensorflow.keras models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36640975",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "TFDS is a set of ready-to-use datasets for various machine learning tasks, including Computer Vision datasets, Natural Language Processing datasets, and miscellaneous other datasets for performing Unsupervised Learning, Reinforcement learning, and more.\n",
    "\n",
    "The entire list of available datasets can be found [here](https://www.tensorflow.org/datasets/catalog/overview). \n",
    "\n",
    "All of these datasets are contained under the `tensorflow.data.Datasets` module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27031432",
   "metadata": {},
   "source": [
    "`Installing TFDS might cause some dependency issues, it is highly recommended to create a new conda env to work on this task.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96114038",
   "metadata": {},
   "source": [
    "To install TFDS:\n",
    "\n",
    "    pip install tensorflow-datasets\n",
    "\n",
    "TFDS is pre-installed in Google Colab, and it can be directly imported as in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fa39686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399eceb5",
   "metadata": {},
   "source": [
    "The following line also displays the list all the available datasets in TFDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf7735fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abstract_reasoning',\n",
       " 'accentdb',\n",
       " 'aeslc',\n",
       " 'aflw2k3d',\n",
       " 'ag_news_subset',\n",
       " 'ai2_arc',\n",
       " 'ai2_arc_with_ir',\n",
       " 'amazon_us_reviews',\n",
       " 'anli',\n",
       " 'answer_equivalence',\n",
       " 'arc',\n",
       " 'asqa',\n",
       " 'asset',\n",
       " 'assin2',\n",
       " 'bair_robot_pushing_small',\n",
       " 'bccd',\n",
       " 'beans',\n",
       " 'bee_dataset',\n",
       " 'beir',\n",
       " 'big_patent',\n",
       " 'bigearthnet',\n",
       " 'billsum',\n",
       " 'binarized_mnist',\n",
       " 'binary_alpha_digits',\n",
       " 'ble_wind_field',\n",
       " 'blimp',\n",
       " 'booksum',\n",
       " 'bool_q',\n",
       " 'bot_adversarial_dialogue',\n",
       " 'bucc',\n",
       " 'c4',\n",
       " 'c4_wsrs',\n",
       " 'caltech101',\n",
       " 'caltech_birds2010',\n",
       " 'caltech_birds2011',\n",
       " 'cardiotox',\n",
       " 'cars196',\n",
       " 'cassava',\n",
       " 'cats_vs_dogs',\n",
       " 'celeb_a',\n",
       " 'celeb_a_hq',\n",
       " 'cfq',\n",
       " 'cherry_blossoms',\n",
       " 'chexpert',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'cifar100_n',\n",
       " 'cifar10_1',\n",
       " 'cifar10_corrupted',\n",
       " 'cifar10_h',\n",
       " 'cifar10_n',\n",
       " 'citrus_leaves',\n",
       " 'cityscapes',\n",
       " 'civil_comments',\n",
       " 'clevr',\n",
       " 'clic',\n",
       " 'clinc_oos',\n",
       " 'cmaterdb',\n",
       " 'cnn_dailymail',\n",
       " 'coco',\n",
       " 'coco_captions',\n",
       " 'coil100',\n",
       " 'colorectal_histology',\n",
       " 'colorectal_histology_large',\n",
       " 'common_voice',\n",
       " 'conll2002',\n",
       " 'conll2003',\n",
       " 'controlled_noisy_web_labels',\n",
       " 'coqa',\n",
       " 'corr2cause',\n",
       " 'cos_e',\n",
       " 'cosmos_qa',\n",
       " 'covid19',\n",
       " 'covid19sum',\n",
       " 'crema_d',\n",
       " 'criteo',\n",
       " 'cs_restaurants',\n",
       " 'curated_breast_imaging_ddsm',\n",
       " 'cycle_gan',\n",
       " 'd4rl_adroit_door',\n",
       " 'd4rl_adroit_hammer',\n",
       " 'd4rl_adroit_pen',\n",
       " 'd4rl_adroit_relocate',\n",
       " 'd4rl_antmaze',\n",
       " 'd4rl_mujoco_ant',\n",
       " 'd4rl_mujoco_halfcheetah',\n",
       " 'd4rl_mujoco_hopper',\n",
       " 'd4rl_mujoco_walker2d',\n",
       " 'dart',\n",
       " 'databricks_dolly',\n",
       " 'davis',\n",
       " 'deep1b',\n",
       " 'deep_weeds',\n",
       " 'definite_pronoun_resolution',\n",
       " 'dementiabank',\n",
       " 'diabetic_retinopathy_detection',\n",
       " 'diamonds',\n",
       " 'div2k',\n",
       " 'dmlab',\n",
       " 'doc_nli',\n",
       " 'dolphin_number_word',\n",
       " 'domainnet',\n",
       " 'downsampled_imagenet',\n",
       " 'drop',\n",
       " 'dsprites',\n",
       " 'dtd',\n",
       " 'duke_ultrasound',\n",
       " 'e2e_cleaned',\n",
       " 'efron_morris75',\n",
       " 'emnist',\n",
       " 'eraser_multi_rc',\n",
       " 'esnli',\n",
       " 'eurosat',\n",
       " 'fashion_mnist',\n",
       " 'flic',\n",
       " 'flores',\n",
       " 'food101',\n",
       " 'forest_fires',\n",
       " 'fuss',\n",
       " 'gap',\n",
       " 'geirhos_conflict_stimuli',\n",
       " 'gem',\n",
       " 'genomics_ood',\n",
       " 'german_credit_numeric',\n",
       " 'gigaword',\n",
       " 'glove100_angular',\n",
       " 'glue',\n",
       " 'goemotions',\n",
       " 'gov_report',\n",
       " 'gpt3',\n",
       " 'gref',\n",
       " 'groove',\n",
       " 'grounded_scan',\n",
       " 'gsm8k',\n",
       " 'gtzan',\n",
       " 'gtzan_music_speech',\n",
       " 'hellaswag',\n",
       " 'higgs',\n",
       " 'hillstrom',\n",
       " 'horses_or_humans',\n",
       " 'howell',\n",
       " 'i_naturalist2017',\n",
       " 'i_naturalist2018',\n",
       " 'i_naturalist2021',\n",
       " 'imagenet2012',\n",
       " 'imagenet2012_corrupted',\n",
       " 'imagenet2012_fewshot',\n",
       " 'imagenet2012_multilabel',\n",
       " 'imagenet2012_real',\n",
       " 'imagenet2012_subset',\n",
       " 'imagenet_a',\n",
       " 'imagenet_lt',\n",
       " 'imagenet_pi',\n",
       " 'imagenet_r',\n",
       " 'imagenet_resized',\n",
       " 'imagenet_sketch',\n",
       " 'imagenet_v2',\n",
       " 'imagenette',\n",
       " 'imagewang',\n",
       " 'imdb_reviews',\n",
       " 'irc_disentanglement',\n",
       " 'iris',\n",
       " 'istella',\n",
       " 'kddcup99',\n",
       " 'kitti',\n",
       " 'kmnist',\n",
       " 'laion400m',\n",
       " 'lambada',\n",
       " 'lfw',\n",
       " 'librispeech',\n",
       " 'librispeech_lm',\n",
       " 'libritts',\n",
       " 'ljspeech',\n",
       " 'lm1b',\n",
       " 'locomotion',\n",
       " 'lost_and_found',\n",
       " 'lsun',\n",
       " 'lvis',\n",
       " 'malaria',\n",
       " 'math_dataset',\n",
       " 'math_qa',\n",
       " 'mctaco',\n",
       " 'media_sum',\n",
       " 'mlqa',\n",
       " 'mnist',\n",
       " 'mnist_corrupted',\n",
       " 'movie_lens',\n",
       " 'movie_rationales',\n",
       " 'movielens',\n",
       " 'moving_mnist',\n",
       " 'mrqa',\n",
       " 'mslr_web',\n",
       " 'mt_opt',\n",
       " 'mtnt',\n",
       " 'multi_news',\n",
       " 'multi_nli',\n",
       " 'multi_nli_mismatch',\n",
       " 'natural_instructions',\n",
       " 'natural_questions',\n",
       " 'natural_questions_open',\n",
       " 'newsroom',\n",
       " 'nsynth',\n",
       " 'nyu_depth_v2',\n",
       " 'ogbg_molpcba',\n",
       " 'omniglot',\n",
       " 'open_images_challenge2019_detection',\n",
       " 'open_images_v4',\n",
       " 'openbookqa',\n",
       " 'opinion_abstracts',\n",
       " 'opinosis',\n",
       " 'opus',\n",
       " 'oxford_flowers102',\n",
       " 'oxford_iiit_pet',\n",
       " 'para_crawl',\n",
       " 'pass',\n",
       " 'patch_camelyon',\n",
       " 'paws_wiki',\n",
       " 'paws_x_wiki',\n",
       " 'penguins',\n",
       " 'pet_finder',\n",
       " 'pg19',\n",
       " 'piqa',\n",
       " 'places365_small',\n",
       " 'placesfull',\n",
       " 'plant_leaves',\n",
       " 'plant_village',\n",
       " 'plantae_k',\n",
       " 'protein_net',\n",
       " 'q_re_cc',\n",
       " 'qa4mre',\n",
       " 'qasc',\n",
       " 'quac',\n",
       " 'quality',\n",
       " 'quickdraw_bitmap',\n",
       " 'race',\n",
       " 'radon',\n",
       " 'real_toxicity_prompts',\n",
       " 'reddit',\n",
       " 'reddit_disentanglement',\n",
       " 'reddit_tifu',\n",
       " 'ref_coco',\n",
       " 'resisc45',\n",
       " 'rlu_atari',\n",
       " 'rlu_atari_checkpoints',\n",
       " 'rlu_atari_checkpoints_ordered',\n",
       " 'rlu_control_suite',\n",
       " 'rlu_dmlab_explore_object_rewards_few',\n",
       " 'rlu_dmlab_explore_object_rewards_many',\n",
       " 'rlu_dmlab_rooms_select_nonmatching_object',\n",
       " 'rlu_dmlab_rooms_watermaze',\n",
       " 'rlu_dmlab_seekavoid_arena01',\n",
       " 'rlu_locomotion',\n",
       " 'rlu_rwrl',\n",
       " 'robomimic_mg',\n",
       " 'robomimic_mh',\n",
       " 'robomimic_ph',\n",
       " 'robonet',\n",
       " 'robosuite_panda_pick_place_can',\n",
       " 'rock_paper_scissors',\n",
       " 'rock_you',\n",
       " 's3o4d',\n",
       " 'salient_span_wikipedia',\n",
       " 'samsum',\n",
       " 'savee',\n",
       " 'scan',\n",
       " 'scene_parse150',\n",
       " 'schema_guided_dialogue',\n",
       " 'sci_tail',\n",
       " 'scicite',\n",
       " 'scientific_papers',\n",
       " 'scrolls',\n",
       " 'segment_anything',\n",
       " 'sentiment140',\n",
       " 'shapes3d',\n",
       " 'sift1m',\n",
       " 'simpte',\n",
       " 'siscore',\n",
       " 'smallnorb',\n",
       " 'smartwatch_gestures',\n",
       " 'snli',\n",
       " 'so2sat',\n",
       " 'speech_commands',\n",
       " 'spoken_digit',\n",
       " 'squad',\n",
       " 'squad_question_generation',\n",
       " 'stanford_dogs',\n",
       " 'stanford_online_products',\n",
       " 'star_cfq',\n",
       " 'starcraft_video',\n",
       " 'stl10',\n",
       " 'story_cloze',\n",
       " 'summscreen',\n",
       " 'sun397',\n",
       " 'super_glue',\n",
       " 'svhn_cropped',\n",
       " 'symmetric_solids',\n",
       " 'tao',\n",
       " 'tatoeba',\n",
       " 'ted_hrlr_translate',\n",
       " 'ted_multi_translate',\n",
       " 'tedlium',\n",
       " 'tf_flowers',\n",
       " 'the300w_lp',\n",
       " 'tiny_shakespeare',\n",
       " 'titanic',\n",
       " 'trec',\n",
       " 'trivia_qa',\n",
       " 'tydi_qa',\n",
       " 'uc_merced',\n",
       " 'ucf101',\n",
       " 'unified_qa',\n",
       " 'universal_dependencies',\n",
       " 'unnatural_instructions',\n",
       " 'user_libri_audio',\n",
       " 'user_libri_text',\n",
       " 'vctk',\n",
       " 'visual_domain_decathlon',\n",
       " 'voc',\n",
       " 'voxceleb',\n",
       " 'voxforge',\n",
       " 'waymo_open_dataset',\n",
       " 'web_graph',\n",
       " 'web_nlg',\n",
       " 'web_questions',\n",
       " 'webvid',\n",
       " 'wider_face',\n",
       " 'wiki40b',\n",
       " 'wiki_auto',\n",
       " 'wiki_bio',\n",
       " 'wiki_dialog',\n",
       " 'wiki_table_questions',\n",
       " 'wiki_table_text',\n",
       " 'wikiann',\n",
       " 'wikihow',\n",
       " 'wikipedia',\n",
       " 'wikipedia_toxicity_subtypes',\n",
       " 'wine_quality',\n",
       " 'winogrande',\n",
       " 'wit',\n",
       " 'wit_kaggle',\n",
       " 'wmt13_translate',\n",
       " 'wmt14_translate',\n",
       " 'wmt15_translate',\n",
       " 'wmt16_translate',\n",
       " 'wmt17_translate',\n",
       " 'wmt18_translate',\n",
       " 'wmt19_translate',\n",
       " 'wmt_t2t_translate',\n",
       " 'wmt_translate',\n",
       " 'wordnet',\n",
       " 'wsc273',\n",
       " 'xnli',\n",
       " 'xquad',\n",
       " 'xsum',\n",
       " 'xtreme_pawsx',\n",
       " 'xtreme_pos',\n",
       " 'xtreme_s',\n",
       " 'xtreme_xnli',\n",
       " 'yahoo_ltrc',\n",
       " 'yelp_polarity_reviews',\n",
       " 'yes_no',\n",
       " 'youtube_vis']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfds.list_builders()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcf627d",
   "metadata": {},
   "source": [
    "### Load Dataset with TFDS \n",
    "\n",
    "The easiest way of loading a dataset with TFDS is with `tfds.load`. \n",
    "\n",
    "It will:\n",
    "\n",
    "1. Download the data and save it as `tfrecord` files.\n",
    "2. Load the `tfrecord` and create the `tf.data.Dataset`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3dbc13ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_data, test_data), info = tfds.load('mnist', with_info=True, shuffle_files=True, as_supervised=True, split=['train', 'test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd14f0f3",
   "metadata": {},
   "source": [
    "Arguments in `tfds.load` include:\n",
    "\n",
    "- First argument is the name of dataset.\n",
    "- param `'split'` controls which split we wish to load (e.g., train, test, or validation).\n",
    "- param `'shuffle_files'` controls whether or not data is shuffled between each epoch.\n",
    "- param `'data_dir'` controls where the dataset is saved (defaults to `~/tensorflow_datasets/`).\n",
    "- param `'with_info'` controls whether or not the metadata for the dataset is included.\n",
    "- param `'as_supervised'` controls whether or not a tuple `(features, label)` is returned (as opposed to just features).\n",
    "- param `'download'` controls whether or not the library will attempt to download the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4338dc1",
   "metadata": {},
   "source": [
    "We can access the dataset metadata with `info` as in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fefda698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='mnist',\n",
      "    full_name='mnist/3.0.1',\n",
      "    description=\"\"\"\n",
      "    The MNIST database of handwritten digits.\n",
      "    \"\"\",\n",
      "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
      "    data_dir='C:\\\\Users\\\\vakanski\\\\tensorflow_datasets\\\\mnist\\\\3.0.1',\n",
      "    file_format=tfrecord,\n",
      "    download_size=11.06 MiB,\n",
      "    dataset_size=21.00 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
      "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
      "    }),\n",
      "    supervised_keys=('image', 'label'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
      "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
      "    },\n",
      "    citation=\"\"\"@article{lecun2010mnist,\n",
      "      title={MNIST handwritten digit database},\n",
      "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
      "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
      "      volume={2},\n",
      "      year={2010}\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3871206e",
   "metadata": {},
   "source": [
    "Features metadata can include features shape, label shape, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b0fc6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FeaturesDict({\n",
       "    'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
       "    'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dcb410",
   "metadata": {},
   "source": [
    "We can also inspect the number of classes and label names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1960f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n"
     ]
    }
   ],
   "source": [
    "print(info.features[\"label\"].num_classes)\n",
    "print(info.features[\"label\"].names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2832bfb",
   "metadata": {},
   "source": [
    "print(info.features.shape)\n",
    "print(info.features.np_dtype)\n",
    "print(info.features['image'].shape)\n",
    "print(info.features['image'].np_dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6fdf34",
   "metadata": {},
   "source": [
    "### Slicing API for Customized Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d23dd992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fashion MNIST dataset, get 25% to 75% of train dataset \n",
    "ds = tfds.load('mnist', split='train[25%:75%]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "98891aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first 4,000 of the data for training\n",
    "ds = tfds.load('fashion_mnist', split='train[:4000]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "482a7e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 25% of training and all of the test data\n",
    "ds = tfds.load('fashion_mnist', split='train[:25%]+test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68368d0a",
   "metadata": {},
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd4a6058",
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_ds = tfds.load('fashion_mnist', split=[\n",
    "    f'train[{k}%:{k+10}%]' for k in range(0, 100, 10)])\n",
    "\n",
    "trains_ds = tfds.load('fashion_mnist', split=[\n",
    "    f'train[:{k}%]+train[{k+10}%:]' for k in range(0, 100, 10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2000580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First fold of validation DS\n",
    "vals_ds_fold1 =vals_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93b5652",
   "metadata": {},
   "source": [
    "### Iterate over the Dataset in Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5094ece0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "img: (32, 28, 28, 1), labels: [4 1 0 7 8 1 2 7 1 6 6 4 7 7 3 3 7 9 9 1 0 6 6 9 9 4 8 9 4 7 3 3]\n",
      "img: (32, 28, 28, 1), labels: [4 1 0 7 8 1 2 7 1 6 6 4 7 7 3 3 7 9 9 1 0 6 6 9 9 4 8 9 4 7 3 3]\n",
      "img: (32, 28, 28, 1), labels: [4 1 0 7 8 1 2 7 1 6 6 4 7 7 3 3 7 9 9 1 0 6 6 9 9 4 8 9 4 7 3 3]\n",
      "img: (32, 28, 28, 1), labels: [4 1 0 7 8 1 2 7 1 6 6 4 7 7 3 3 7 9 9 1 0 6 6 9 9 4 8 9 4 7 3 3]\n",
      "img: (32, 28, 28, 1), labels: [4 1 0 7 8 1 2 7 1 6 6 4 7 7 3 3 7 9 9 1 0 6 6 9 9 4 8 9 4 7 3 3]\n",
      "img: (32, 28, 28, 1), labels: [4 1 0 7 8 1 2 7 1 6 6 4 7 7 3 3 7 9 9 1 0 6 6 9 9 4 8 9 4 7 3 3]\n",
      "img: (32, 28, 28, 1), labels: [4 1 0 7 8 1 2 7 1 6 6 4 7 7 3 3 7 9 9 1 0 6 6 9 9 4 8 9 4 7 3 3]\n",
      "img: (32, 28, 28, 1), labels: [4 1 0 7 8 1 2 7 1 6 6 4 7 7 3 3 7 9 9 1 0 6 6 9 9 4 8 9 4 7 3 3]\n",
      "img: (32, 28, 28, 1), labels: [4 1 0 7 8 1 2 7 1 6 6 4 7 7 3 3 7 9 9 1 0 6 6 9 9 4 8 9 4 7 3 3]\n",
      "img: (32, 28, 28, 1), labels: [4 1 0 7 8 1 2 7 1 6 6 4 7 7 3 3 7 9 9 1 0 6 6 9 9 4 8 9 4 7 3 3]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "for epoch in range(1):\n",
    "    print(f'epoch {epoch}')   \n",
    "    n = 0\n",
    "    for img, label in training_data.batch(batch_size):\n",
    "        # print the first 10 batches\n",
    "        while n < 10:\n",
    "            # notice that img.shape = [batch size, pixels width, pixels heights, channels number)\n",
    "            # notice that label.shape = 32, therefore 32 labels are shown\n",
    "            print(f'img: {img.shape}, labels: {label}') \n",
    "            # we can train a model here\n",
    "            n = n+1            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4431572b",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e487193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_fff22\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_fff22_level0_col0\" class=\"col_heading level0 col0\" >image</th>\n",
       "      <th id=\"T_fff22_level0_col1\" class=\"col_heading level0 col1\" >label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_fff22_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_fff22_row0_col0\" class=\"data row0 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAzElEQVR4nGNgGPQg5F8qjMmEIRn1XwinRvnvp2QxdTIyMjAwMDDksd17jCnpeN6CgYGBQZfhAhbzLP+WMzAwyPz8IAkXQuh8ycDAwMAQyHr1ORZJYQYGBgYGKYYDDFgkAxgZGBikMxnnISQZYQz2J0KXjwvpqV00+YfpnsS/f//++/v3bxiSGAuMYfp97rN3b1cz7MDiEQgI+bcGmYsatlH/T+PUyPD2jwVOOaOP23Br3P3vZyZOO///v7qGARd4/EkBt7FvbuOWoyIAAPBxN9oBRuu9AAAAAElFTkSuQmCC\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_fff22_row0_col1\" class=\"data row0 col1\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fff22_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_fff22_row1_col0\" class=\"data row1 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAmklEQVR4nGNgGOyAc/5KJlxyjIv+/TPEJan9798HWRgH3YhQBoZHj3HpfP/vVxQuOYF//54ieGjGNjEwXMalkeHbv3+eeCTfseAy1oCVYeofXBp3/f8lgUtO/su/azhtnPLvXwJOycv//uGU0//5bx1OySP//hngkuN5+u8tG4oIkj/VJBmO/8Il6cvAMBunlSIvX3DjlKQmAACHtTHZmy2LVAAAAABJRU5ErkJggg==\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_fff22_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fff22_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_fff22_row2_col0\" class=\"data row2 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA+0lEQVR4nM3QvyuEARzH8feVniSFiTBcKf8A85ESNqwkdbeY5NdmY/UXiM0z+Ad0SXZ1g0vJjw0Xi86pc13eD8NleJ47q3zG76tv3x/wJxk+jQ7bf8NldT9obdNl1fWW1nGh6mtLPIm0oJVWlvuIvOvMWx1qtqWa0U2aULNNNnCtT+MQapi0waK6CoR6mcS8Wuhq4Fqj1PZjU5NQnX0DUine433dD1qZBwjOrM/EsVc9AmCj6c5MWT8XADjX2mgMi+otABN1k0/YVncAFu/VLWLbPgNBduRxLBMQHe/FZ+Zs5EtLm8kP9F81MHrZTScNelZK6sFcXzP9o3wDadaKxdoXqEQAAAAASUVORK5CYII=\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_fff22_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fff22_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_fff22_row3_col0\" class=\"data row3 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA40lEQVR4nGNgGJpg//8OdCEWKM2obvgv/++6/zcZnJQebPuNqkjvLxI4IIgiJ3/v79/3b//9/fvv7993f/9NQzE2TZ6hc8J3JwYGBgaGK7cYeJE12n79+1cCxlH9+/cVB5LOlxy/pryHSUYyMO78gSR5W/vzU7gxfAz/cfq36fvfDw445Fr+/P3bg12KMebb37+7WbDKKSz89/fvNRmscjpb//79u0YBq5z0yb9//2bhcEvXv78fs1ixyzX//PsuHYc+gbvwAMcEmX//3kFzJxOc9YCRoesJLp3sx9+p4JIjGQAAnrpmBs0pxioAAAAASUVORK5CYII=\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_fff22_row3_col1\" class=\"data row3 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_fff22_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_fff22_row4_col0\" class=\"data row4 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABRUlEQVR4nM2RMUgCcRTGvwvFjjiuhqgIpG4Kg8QaQi6aWoo2JXAot6ZokxwdGxybWjJoapLCQRoaJBKkoIJuKDc7DAruIEmH967hvPJ/Nkdv+vh+fI//+/7Afxglyy+qK6UeW1MSg5p2twVp4lUMhGYuLSYiJiIec72AlzqNAVf1klUGYLaF3BqzXdQBbLJtc0Fgsx26ngQARA72miQLMEU08qM/PDkAAIgBC56TQV58apSZ+ex4Pw6k2fQdHly9fSYi7phmi6pRz/4uQZleVyUnPSo5wEPmAv2zYlFto9BgS+tnuRZXNGCJec6PgiWmExXALt8HRDS+U3n6zMkAhgxOCUg+YqJyEgAQp4bayxZr7OS7HYXfebtru8sT8w4MJQwAena4fihsjRjE9Ob+Zftc8ZUQWtan5KTkPN40i9VfCvi7+QIpz4HjFNztwwAAAABJRU5ErkJggg==\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_fff22_row4_col1\" class=\"data row4 col1\" >8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "                                               image  label\n",
       "0  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      4\n",
       "1  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      1\n",
       "2  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      0\n",
       "3  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      7\n",
       "4  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      8"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list 5 images and labels from mnist dataset\n",
    "ds, info = tfds.load('mnist', split='train', with_info=True)\n",
    "\n",
    "tfds.as_dataframe(ds.take(5), info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fb81db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_f7e53\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_f7e53_level0_col0\" class=\"col_heading level0 col0\" >image</th>\n",
       "      <th id=\"T_f7e53_level0_col1\" class=\"col_heading level0 col1\" >label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_f7e53_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_f7e53_row0_col0\" class=\"data row0 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAzElEQVR4nGNgGPQg5F8qjMmEIRn1XwinRvnvp2QxdTIyMjAwMDDksd17jCnpeN6CgYGBQZfhAhbzLP+WMzAwyPz8IAkXQuh8ycDAwMAQyHr1ORZJYQYGBgYGKYYDDFgkAxgZGBikMxnnISQZYQz2J0KXjwvpqV00+YfpnsS/f//++/v3bxiSGAuMYfp97rN3b1cz7MDiEQgI+bcGmYsatlH/T+PUyPD2jwVOOaOP23Br3P3vZyZOO///v7qGARd4/EkBt7FvbuOWoyIAAPBxN9oBRuu9AAAAAElFTkSuQmCC\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_f7e53_row0_col1\" class=\"data row0 col1\" >4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7e53_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_f7e53_row1_col0\" class=\"data row1 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAmklEQVR4nGNgGOyAc/5KJlxyjIv+/TPEJan9798HWRgH3YhQBoZHj3HpfP/vVxQuOYF//54ieGjGNjEwXMalkeHbv3+eeCTfseAy1oCVYeofXBp3/f8lgUtO/su/azhtnPLvXwJOycv//uGU0//5bx1OySP//hngkuN5+u8tG4oIkj/VJBmO/8Il6cvAMBunlSIvX3DjlKQmAACHtTHZmy2LVAAAAABJRU5ErkJggg==\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_f7e53_row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7e53_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_f7e53_row2_col0\" class=\"data row2 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA+0lEQVR4nM3QvyuEARzH8feVniSFiTBcKf8A85ESNqwkdbeY5NdmY/UXiM0z+Ad0SXZ1g0vJjw0Xi86pc13eD8NleJ47q3zG76tv3x/wJxk+jQ7bf8NldT9obdNl1fWW1nGh6mtLPIm0oJVWlvuIvOvMWx1qtqWa0U2aULNNNnCtT+MQapi0waK6CoR6mcS8Wuhq4Fqj1PZjU5NQnX0DUine433dD1qZBwjOrM/EsVc9AmCj6c5MWT8XADjX2mgMi+otABN1k0/YVncAFu/VLWLbPgNBduRxLBMQHe/FZ+Zs5EtLm8kP9F81MHrZTScNelZK6sFcXzP9o3wDadaKxdoXqEQAAAAASUVORK5CYII=\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_f7e53_row2_col1\" class=\"data row2 col1\" >0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7e53_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_f7e53_row3_col0\" class=\"data row3 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA40lEQVR4nGNgGJpg//8OdCEWKM2obvgv/++6/zcZnJQebPuNqkjvLxI4IIgiJ3/v79/3b//9/fvv7993f/9NQzE2TZ6hc8J3JwYGBgaGK7cYeJE12n79+1cCxlH9+/cVB5LOlxy/pryHSUYyMO78gSR5W/vzU7gxfAz/cfq36fvfDw445Fr+/P3bg12KMebb37+7WbDKKSz89/fvNRmscjpb//79u0YBq5z0yb9//2bhcEvXv78fs1ixyzX//PsuHYc+gbvwAMcEmX//3kFzJxOc9YCRoesJLp3sx9+p4JIjGQAAnrpmBs0pxioAAAAASUVORK5CYII=\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_f7e53_row3_col1\" class=\"data row3 col1\" >7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_f7e53_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_f7e53_row4_col0\" class=\"data row4 col0\" ><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABRUlEQVR4nM2RMUgCcRTGvwvFjjiuhqgIpG4Kg8QaQi6aWoo2JXAot6ZokxwdGxybWjJoapLCQRoaJBKkoIJuKDc7DAruIEmH967hvPJ/Nkdv+vh+fI//+/7Afxglyy+qK6UeW1MSg5p2twVp4lUMhGYuLSYiJiIec72AlzqNAVf1klUGYLaF3BqzXdQBbLJtc0Fgsx26ngQARA72miQLMEU08qM/PDkAAIgBC56TQV58apSZ+ex4Pw6k2fQdHly9fSYi7phmi6pRz/4uQZleVyUnPSo5wEPmAv2zYlFto9BgS+tnuRZXNGCJec6PgiWmExXALt8HRDS+U3n6zMkAhgxOCUg+YqJyEgAQp4bayxZr7OS7HYXfebtru8sT8w4MJQwAena4fihsjRjE9Ob+Zftc8ZUQWtan5KTkPN40i9VfCvi7+QIpz4HjFNztwwAAAABJRU5ErkJggg==\" alt=\"Img\" /></td>\n",
       "      <td id=\"T_f7e53_row4_col1\" class=\"data row4 col1\" >8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "                                               image  label\n",
       "0  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      4\n",
       "1  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      1\n",
       "2  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      0\n",
       "3  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      7\n",
       "4  [[[0], [0], [0], [0], [0], [0], [0], [0], [0],...      8"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list 5 images and labels from mnist dataset\n",
    "tfds.as_dataframe(ds.take(5), info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96da9b55",
   "metadata": {},
   "source": [
    "Method 2: `tfds.show_examples` returns a matplotlib figure with data samples and labels (only image datasets are supported with this method)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5b39ac4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x900 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = tfds.show_examples(ds, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0824225f",
   "metadata": {},
   "source": [
    "### Create Your Own TFDS with `tf.data.Dataset.from_tensor_slices`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a3bfe4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, x_batch shape: (5, 100, 100), y_batch shape: (5, 1)\n",
      "step: 1, x_batch shape: (5, 100, 100), y_batch shape: (5, 1)\n",
      "step: 2, x_batch shape: (5, 100, 100), y_batch shape: (5, 1)\n",
      "step: 3, x_batch shape: (5, 100, 100), y_batch shape: (5, 1)\n",
      "step: 4, x_batch shape: (5, 100, 100), y_batch shape: (5, 1)\n",
      "step: 5, x_batch shape: (5, 100, 100), y_batch shape: (5, 1)\n",
      "step: 6, x_batch shape: (2, 100, 100), y_batch shape: (2, 1)\n",
      "\n",
      "step: 0, x_batch shape: (5, 100, 100), y_batch shape: (5, 1)\n",
      "step: 1, x_batch shape: (5, 100, 100), y_batch shape: (5, 1)\n",
      "step: 2, x_batch shape: (5, 100, 100), y_batch shape: (5, 1)\n",
      "step: 3, x_batch shape: (5, 100, 100), y_batch shape: (5, 1)\n",
      "step: 4, x_batch shape: (5, 100, 100), y_batch shape: (5, 1)\n",
      "step: 5, x_batch shape: (5, 100, 100), y_batch shape: (5, 1)\n",
      "step: 6, x_batch shape: (2, 100, 100), y_batch shape: (2, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "features = np.random.uniform(0,1, size=(32, 100, 100))\n",
    "labels = np.random.randint(0, 2, size=(32, 1))\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((features, labels))\n",
    "dataset = dataset.shuffle(buffer_size=1024).batch(5)  \n",
    "\n",
    "for epoch in range(2):\n",
    "    for step, (x_batch, y_batch) in enumerate(dataset):\n",
    "        print(f'step: {step}, x_batch shape: {x_batch.shape}, y_batch shape: {y_batch.shape}')\n",
    "    print()        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367b15d0",
   "metadata": {},
   "source": [
    "### Simple Example of a Pipeline with TFDS in a CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6dc34561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "33/33 [==============================] - 15s 414ms/step - loss: 3.3552 - accuracy: 0.5151 - val_loss: 0.6936 - val_accuracy: 0.4375\n",
      "Epoch 2/3\n",
      "33/33 [==============================] - 13s 401ms/step - loss: 0.6617 - accuracy: 0.5492 - val_loss: 8.1690 - val_accuracy: 0.4375\n",
      "Epoch 3/3\n",
      "33/33 [==============================] - 15s 464ms/step - loss: 0.6275 - accuracy: 0.5628 - val_loss: 4.4311 - val_accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# MODEL DEFINITION \n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(12, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# EXTRACT PHASE \n",
    "data = tfds.load('horses_or_humans', split='train', as_supervised=True)\n",
    "val_data = tfds.load('horses_or_humans', split='test', as_supervised=True)\n",
    "\n",
    "# TRANSFORM PHASE \n",
    "def augmentimages(image, label):\n",
    "  image = tf.cast(image, tf.float32)\n",
    "  image = (image/255)\n",
    "  image = tf.image.random_flip_left_right(image)\n",
    "  return image, label\n",
    "\n",
    "train = data.map(augmentimages)\n",
    "train_batches = train.shuffle(100).batch(32)\n",
    "validation_batches = val_data.batch(32)\n",
    "\n",
    "# MODEL TRAINING PHASE\n",
    "history = model.fit(train_batches, epochs=3, \n",
    "                    validation_data=validation_batches, validation_steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd7be41",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "1. Moroney, L. (n.d.). AI and Machine Learning for Coders. O’Reilly Online Learning. https://www.oreilly.com/library/view/ai-and-machine/9781492078180/ch04.html \n",
    "2. Tensorflow datasets. TensorFlow. (n.d.). https://www.tensorflow.org/datasets/overview#iterate_over_a_dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2910aa3-43ff-4edc-a0a8-f50ab6c43648",
   "metadata": {},
   "source": [
    "[BACK TO TOP](#top)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
